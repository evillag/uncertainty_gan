{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1hFC265XMru8NyovZG-RP9zceMgI-172X",
   "authorship_tag": "ABX9TyNsad50yqU8EhmxZEkTaQr2",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/evillag/uncertainty_gan/blob/main/CERN_UE_Output_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model"
   ],
   "metadata": {
    "id": "Vfsi-ed4caCm",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:20.323377Z",
     "start_time": "2024-06-02T21:03:20.316384Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
    "!mv lhcb-rich-gan-uncertainty/experiments .\n",
    "!mv lhcb-rich-gan-uncertainty/src .\n",
    "!rm -r lhcb-rich-gan-uncertainty/\n",
    "!rm -r sample_data/\n",
    "!pip install tensorflow-addons"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:24.884163Z",
     "start_time": "2024-06-02T21:03:22.371613Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tensorflow-addon",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\esteb\\.conda\\envs\\tf\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\esteb\\.conda\\envs\\tf\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\esteb\\.conda\\envs\\tf\\lib\\site-packages (from tensorflow-addons) (23.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for matplotlib: [Errno 2] No such file or directory: 'c:\\\\users\\\\esteb\\\\.conda\\\\envs\\\\tf\\\\lib\\\\site-packages\\\\matplotlib-3.7.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\\\users\\\\esteb\\\\.conda\\\\envs\\\\tf\\\\lib\\\\site-packages\\\\numpy-1.24.3.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "from src.cramer_gan_trainer import CramerGANTrainer\n",
    "from src.datasets.utils_rich import (get_merged_typed_dataset,\n",
    "                                     parse_dataset_np)\n",
    "from src.models.gans.discriminators.fcn_disc import RICHDiscriminator\n",
    "from src.models.gans.generators.fcn_gen import RichMCDropFunc, VirtualEnsembleModel"
   ],
   "metadata": {
    "id": "j4tFqIwachJ7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "db97a5c2-d2fc-401c-f09a-9e7b38b0a7db",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:24.900162Z",
     "start_time": "2024-06-02T21:03:24.886163Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset download and extraction\n",
    "!unzip -qq drive/MyDrive/cern/data/rich.zip"
   ],
   "metadata": {
    "id": "TklyNidOCDK_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Model checkpoint download and extraction\n",
    "!unzip -qq drive/MyDrive/cern/data/checkpoints_dropout_0.01.zip"
   ],
   "metadata": {
    "id": "VDWma3_Ok0jx"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "PARTICLES = ['proton'] # [\"pion\", \"kaon\", \"muon\", \"proton\"]\n",
    "\n",
    "DATA_DIR = 'rich'\n",
    "CHECKPOINT_BASE = 'checkpoints'\n",
    "\n",
    "\n",
    "\n",
    "def get_checkpoint_name(particle):\n",
    "    return f'bernoulli_structured_dropout_line_test_cramer_drop_rate_0.01_{particle}'"
   ],
   "metadata": {
    "id": "E6kdyUS4dB53",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:25.789922Z",
     "start_time": "2024-06-02T21:03:25.771928Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def _split_by_line(df, slope=1, intercept=0):\n",
    "    top_half = df[df['Brunel_ETA'] > df['Brunel_P'] * slope + intercept]\n",
    "    bottom_half = df[df['Brunel_ETA'] <= df['Brunel_P'] * slope + intercept]\n",
    "\n",
    "    top_half = top_half.reset_index(drop=True)\n",
    "    bottom_half = bottom_half.reset_index(drop=True)\n",
    "\n",
    "    return top_half, bottom_half\n",
    "\n",
    "\n",
    "def split_by_line(df_train, df_test):\n",
    "    return _split_by_line(df_train)[0], _split_by_line(df_test)[1]\n",
    "\n",
    "\n",
    "def load_particle_datasets(particle, data_dir=DATA_DIR):\n",
    "    \"\"\" The returned dictionary has this format:\n",
    "        {\n",
    "          \"<particle_name>\": {\n",
    "            'data_train': data_train,\n",
    "            'data_val': data_val,\n",
    "            'scaler': scaler,\n",
    "            'feats_train': feats_train,\n",
    "            'targets_train': targets_train,\n",
    "            'feats_val': feats_val,\n",
    "            'targets_val': targets_val\n",
    "          }\n",
    "        }\n",
    "    \"\"\"\n",
    "    data_train, data_val, scaler = get_merged_typed_dataset(data_dir, particle, dtype=np.float32, log=True,\n",
    "                                                            sample_fn=split_by_line)\n",
    "    feats_train, targets_train, _ = parse_dataset_np(data_train)\n",
    "    feats_val, targets_val, _ = parse_dataset_np(data_val)\n",
    "\n",
    "    print(f'feats_train shape\\t{feats_train.shape}\\n'\n",
    "          f'targets_train shape\\t{targets_train.shape}\\n'\n",
    "          f'feats_val shape  \\t{feats_val.shape}\\n'\n",
    "          f'targets_val shape\\t{targets_val.shape}\\n')\n",
    "\n",
    "    return {\n",
    "        'data_train': data_train,\n",
    "        'data_val': data_val,\n",
    "        'scaler': scaler,\n",
    "        'feats_train': feats_train,\n",
    "        'targets_train': targets_train,\n",
    "        'feats_val': feats_val,\n",
    "        'targets_val': targets_val\n",
    "    }\n",
    "\n",
    "datasets = {particle: load_particle_datasets(particle) for particle in PARTICLES}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zk-zDebdbfh",
    "outputId": "51ebe68b-6bea-42cd-9f17-2eecab788f52",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:37.771183Z",
     "start_time": "2024-06-02T21:03:28.460457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and concatenating datasets:\n",
      "\t../data/rich\\proton_+_down_2016_.csv\n",
      "\t../data/rich\\proton_+_up_2016_.csv\n",
      "\t../data/rich\\proton_-_down_2016_.csv\n",
      "\t../data/rich\\proton_-_up_2016_.csv\n",
      "splitting to train/val/test\n",
      "fitting the scaler\n",
      "scaler train sample size: 1000000\n",
      "scaler n_quantiles: 100000, time = 0.9000041484832764\n",
      "scaling train set\n",
      "scaling test set\n",
      "converting dtype to <class 'numpy.float32'>\n",
      "feats_train shape\t(454724, 3)\n",
      "targets_train shape\t(454724, 5)\n",
      "feats_val shape  \t(272832, 3)\n",
      "targets_val shape\t(272832, 5)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "class MonteCarloDroupoutModel:\n",
    "    def __init__(self, particle, dropout_rate,\n",
    "                 log_dir='log_dir_tmp',\n",
    "                 checkpoint_dir=CHECKPOINT_BASE,\n",
    "                 debug=False):\n",
    "\n",
    "        self.particle = particle\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.log_dir = log_dir\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "\n",
    "        print(f'Generating model for {particle} with a dropout rate of {dropout_rate}')\n",
    "\n",
    "        self._gen_config = {\n",
    "            'drop_rate': dropout_rate,\n",
    "            'dropout_type': 'bernoulli',\n",
    "        }\n",
    "\n",
    "        self._generator = RichMCDropFunc(**self._gen_config)\n",
    "        self._generator.build((None, 3))\n",
    "        self._discriminator = RICHDiscriminator()\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\nGenerator:\\n\")\n",
    "            print(self._generator.summary(line_length=96))\n",
    "            print(\"\\nDiscriminator:\\n\")\n",
    "            print(self._discriminator.summary())\n",
    "            print(f\"\\nCheckpoint path: {self.checkpoint_dir}\\n\")\n",
    "\n",
    "        # Model was trained with tensorflow 2.10.1, use the legacy optimizer\n",
    "        self._generator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
    "        self._discriminator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
    "\n",
    "        self._trainer_config = {\n",
    "            'generator': self._generator,\n",
    "            'discriminator': self._discriminator,\n",
    "            'generator_optimizer': self._generator_optimizer,\n",
    "            'discriminator_optimizer': self._discriminator_optimizer,\n",
    "            'checkpoint_dir': self.checkpoint_dir,\n",
    "            'log_dir': log_dir\n",
    "        }\n",
    "\n",
    "        trainer = CramerGANTrainer(**self._trainer_config)\n",
    "        # Restore pretrained model\n",
    "        trainer.restore_last()\n",
    "\n",
    "    def str(self):\n",
    "        return f\"{self.particle}_{self.dropout_rate}\"\n",
    "\n",
    "    def get_generator(self) -> VirtualEnsembleModel:\n",
    "        return self._generator"
   ],
   "metadata": {
    "id": "1rxa9QaXd6qQ",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:37.787182Z",
     "start_time": "2024-06-02T21:03:37.773184Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "mc_model = MonteCarloDroupoutModel('proton', .01, debug=True)\n",
    "gen1 = mc_model.get_generator()\n",
    "gen1.single_model_inference_mode()\n",
    "gen1.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdyAQi-VeHHD",
    "outputId": "8c8b01e7-dee8-4d06-b74d-4787d2a57d16",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:38.180706Z",
     "start_time": "2024-06-02T21:03:37.788182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating model for proton with a dropout rate of 0.01\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "\n",
      "Generator:\n",
      "\n",
      "Model: \"virtual_ensemble_model_1\"\n",
      "________________________________________________________________________________________________\n",
      " Layer (type)                              Output Shape                          Param #        \n",
      "================================================================================================\n",
      " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
      "                                                                                                \n",
      " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
      "                                                                                                \n",
      " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
      "                                                                                                \n",
      " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " DensePrediction (Dense)                   (None, 5)                             645            \n",
      "                                                                                                \n",
      "================================================================================================\n",
      "Total params: 75,397\n",
      "Trainable params: 75,397\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Discriminator:\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8)            0           ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 256)          100224      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100,224\n",
      "Trainable params: 100,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Checkpoint path: ../checkpoints\n",
      "\n",
      "0.001\n",
      "Last ckpt:  None\n",
      "Model: \"virtual_ensemble_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputs (InputLayer)         [(None, 3)]               0         \n",
      "                                                                 \n",
      " NoiseInjection (NoiseInject  (None, 67)               0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " Layer_0/Dense (Dense)       (None, 128)               8704      \n",
      "                                                                 \n",
      " Layer_0/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_0/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_1/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_1/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_1/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_2/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_2/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_2/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_3/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_3/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_3/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_4/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_4/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_4/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " DensePrediction (Dense)     (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,397\n",
      "Trainable params: 75,397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def create_generator(dropout_rate, dropout_type='bernoulli'):\n",
    "    gen_config = {\n",
    "        'drop_rate': dropout_rate,\n",
    "        'dropout_type': dropout_type,\n",
    "    }\n",
    "    generator = RichMCDropFunc(**gen_config)\n",
    "    generator.build((None, 3))\n",
    "    generator.single_model_inference_mode()\n",
    "    return generator"
   ],
   "metadata": {
    "id": "QkQtLhOsfm2E",
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:38.196704Z",
     "start_time": "2024-06-02T21:03:38.181705Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:52.362174Z",
     "start_time": "2024-06-02T21:03:52.175652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Solution to read embeddings of any layer:\n",
    "\n",
    "# 1. Create a new model with the same architecture\n",
    "new_gen = create_generator(.01)\n",
    "new_gen.set_weights(gen1.get_weights())\n",
    "\n",
    "# 2. Create a new model that outputs from the layer of interest\n",
    "input_layer = new_gen.input\n",
    "output_layer = new_gen.layers[14].output  # Index is 14 because layer indexing starts from 0\n",
    "\n",
    "# 3. Create a `new_model` without optimizations\n",
    "new_model = Model(input_layer, [output_layer, new_gen.output])\n",
    "print(new_model.summary())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputs (InputLayer)         [(None, 3)]               0         \n",
      "                                                                 \n",
      " NoiseInjection (NoiseInject  (None, 67)               0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " Layer_0/Dense (Dense)       (None, 128)               8704      \n",
      "                                                                 \n",
      " Layer_0/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_0/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_1/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_1/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_1/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_2/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_2/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_2/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_3/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_3/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_3/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " Layer_4/Dense (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Layer_4/LeakyReLU (LeakyReL  (None, 128)              0         \n",
      " U)                                                              \n",
      "                                                                 \n",
      " Layer_4/DropoutTrain (Dropo  (None, 128)              0         \n",
      " utTrain)                                                        \n",
      "                                                                 \n",
      " DensePrediction (Dense)     (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,397\n",
      "Trainable params: 75,397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T21:03:57.261885Z",
     "start_time": "2024-06-02T21:03:56.392395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Use `new_model` to predict on any input vector and get the embeddings\n",
    "input_data = np.random.rand(1, 3)\n",
    "embedding, prediction = new_model.predict(input_data)\n",
    "\n",
    "original_model_prediction = gen1.predict(input_data)\n",
    "\n",
    "print(f'Layer 4 {embedding.shape} embedding:\\n{embedding}')\n",
    "print('Final prediction:', prediction)\n",
    "print('Final prediction:', original_model_prediction)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 658ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Layer 4 (1, 128) embedding:\n",
      "[[ 0.12764037 -0.01327349  0.17507285 -0.344127    0.08596199  0.20315282\n",
      "   0.0594095  -0.03482367  0.19064844  0.29219687 -0.06622943 -0.08309644\n",
      "   0.08323199 -0.04771329 -0.07798733 -0.14236856  0.09624968  0.11993797\n",
      "   0.02152829  0.00098584  0.12419684 -0.11989795  0.03352994  0.14096555\n",
      "   0.08627124  0.18926719 -0.00098421  0.10983233  0.16482729  0.14274658\n",
      "  -0.12298921  0.0275607   0.16230041 -0.13765405  0.03598827  0.06871919\n",
      "   0.2860038  -0.07886286 -0.00436414 -0.01309698 -0.38272    -0.03287196\n",
      "   0.19416624 -0.00488659 -0.07617358  0.2607302  -0.10444013 -0.03424028\n",
      "  -0.15424722  0.14431304  0.06090955  0.03464188  0.14550951  0.06849828\n",
      "   0.08043085  0.29488727  0.08121265 -0.13358432  0.07076782 -0.14085089\n",
      "   0.00258403  0.02730661  0.13409364 -0.00519869  0.13262329 -0.00497463\n",
      "  -0.31768432 -0.11523663  0.3876856   0.21075398 -0.05978448 -0.09931962\n",
      "  -0.43261117 -0.09011538  0.09897996  0.21876644 -0.03022487  0.17012027\n",
      "   0.07865405 -0.2873643   0.10197449  0.13164425 -0.2586039  -0.15341452\n",
      "   0.10724299  0.06606492 -0.10309129 -0.27696505  0.19173285 -0.2090188\n",
      "  -0.0710703  -0.05988396 -0.0223069   0.20301108  0.16880754  0.15265392\n",
      "   0.06834497  0.20044406 -0.14345564 -0.05657053 -0.12073498  0.03045614\n",
      "  -0.21717441  0.16306527  0.22712536  0.24400097  0.04486825 -0.32997203\n",
      "  -0.05826867  0.3311481   0.08135165  0.02484891 -0.25042263 -0.08964331\n",
      "   0.17788173  0.29773453 -0.08299746 -0.03189387  0.09546265  0.22787045\n",
      "   0.00596519 -0.25205323 -0.08320859  0.23474242 -0.03994605  0.0642598\n",
      "   0.35536808  0.01221019]]\n",
      "Final prediction: [[-0.25890648  0.00526641 -0.23894522  0.19806108  0.00404857]]\n",
      "Final prediction: [[-0.17843366 -0.096835   -0.29225445  0.22706708 -0.01692411]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "dir = 'drive/MyDrive/Colab Notebooks/outputs/proton/'\n",
    "\n",
    "dataset = datasets['proton']\n",
    "\n",
    "train_feats = dataset['feats_train']\n",
    "train_targets = dataset['targets_train']\n",
    "test_feats = dataset['feats_val']\n",
    "test_targets = dataset['targets_val']\n",
    "\n",
    "print('Train features shape:', train_feats.shape)\n",
    "print('Train targets shape:', train_targets.shape)\n",
    "print('Test features shape:', test_feats.shape)\n",
    "print('Test targets shape:', test_targets.shape)\n",
    "\n",
    "np.save(dir + 'train_feats.npy', train_feats)\n",
    "np.save(dir + 'train_targets.npy', train_targets)\n",
    "np.save(dir + 'test_feats.npy', test_feats)\n",
    "np.save(dir + 'test_targets.npy', test_targets)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qjt-dAjTieWX",
    "outputId": "461fbdae-ee3f-44a4-972c-e30399edec04"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_embeddings, train_predictions = new_model.predict(train_feats)\n",
    "test_embeddings, test_predictions = new_model.predict(test_feats)\n",
    "\n",
    "np.save(dir + 'train_embeddings.npy', train_embeddings)\n",
    "np.save(dir + 'train_predictions.npy', train_predictions)\n",
    "np.save(dir + 'test_embeddings.npy', test_embeddings)\n",
    "np.save(dir + 'test_predictions.npy', test_predictions)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqcVEKBEhqn7",
    "outputId": "26044d2d-5cc9-495a-efe2-05b7f3bc0dd3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "_____________________________________\n",
    "tests"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.datasets.utils_rich import dll_columns\n",
    "\n",
    "num_iterations = 300\n",
    "preds = []\n",
    "for i in range(num_iterations):\n",
    "    _, prediction = new_model.predict(input_data)\n",
    "    preds.append(prediction)\n",
    "\n",
    "print('Par\\t'+'\\t'.join(dll_columns))\n",
    "print('Min\\t'+'\\t'.join([str(num) for num in np.min(preds, axis=0).squeeze()]))\n",
    "print(f'Max\\t'+'\\t'.join([str(num) for num in np.max(preds, axis=0).squeeze()]))\n",
    "print(f'Std\\t'+'\\t'.join([str(num) for num in np.std(preds, axis=0).squeeze()]))\n",
    "print(f'Mea\\t'+'\\t'.join([str(num) for num in np.mean(preds, axis=0).squeeze()]))\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
