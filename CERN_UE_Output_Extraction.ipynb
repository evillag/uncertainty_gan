{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hFC265XMru8NyovZG-RP9zceMgI-172X",
      "authorship_tag": "ABX9TyNe/D2LtwJIPq2rDNYo1WdO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/uncertainty_gan/blob/main/CERN_UE_Output_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Vfsi-ed4caCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuSLTKXzcFiS",
        "outputId": "282bc375-4db1-4a60-82fa-58bb34049ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lhcb-rich-gan-uncertainty'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Total 210 (delta 0), reused 0 (delta 0), pack-reused 210 (from 1)\u001b[K\n",
            "Receiving objects: 100% (210/210), 2.94 MiB | 25.96 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
        "!mv lhcb-rich-gan-uncertainty/experiments .\n",
        "!mv lhcb-rich-gan-uncertainty/src .\n",
        "!rm -r lhcb-rich-gan-uncertainty/\n",
        "!rm -r sample_data/\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experiments.efficiency.uncertainty_model_train import train_model\n",
        "from experiments.efficiency.uncertainty_models import uncertainty_mlp\n",
        "from experiments.efficiency.uncertainty_utils import (\n",
        "    efficiency_bands_with_uncertainty, efficiency_momentum_with_uncertainty)\n",
        "from experiments.efficiency.utils import (\n",
        "    efficiency_bands, efficiency_momentum, ensemble_and_ref_model_inference,\n",
        "    ensemble_and_ref_model_inference_on_bands, tf_to_numpy_dataset,\n",
        "    threshold_selection)\n",
        "from src.cramer_gan_trainer import CramerGANTrainer\n",
        "from src.dataset import CramerGANDataset\n",
        "from src.datasets.utils_rich import (get_merged_typed_dataset,\n",
        "                                     parse_dataset_np, parse_example)\n",
        "from src.models.gans.discriminators.fcn_disc import RICHDiscriminator\n",
        "from src.models.gans.generators.fcn_gen import RichMCDropFunc, VirtualEnsembleModel"
      ],
      "metadata": {
        "id": "j4tFqIwachJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b502267f-dfc0-4741-c97b-5396a5d0a385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset download and extraction\n",
        "!unzip -qq drive/MyDrive/cern/data/rich.zip"
      ],
      "metadata": {
        "id": "TklyNidOCDK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model checkpoint download and extraction\n",
        "!unzip -qq drive/MyDrive/cern/data/checkpoints.zip"
      ],
      "metadata": {
        "id": "fAWf7Pw3kz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (New) model checkpoint download and extraction\n",
        "!unzip -qq drive/MyDrive/cern/data/new_checkpoints.zip"
      ],
      "metadata": {
        "id": "VDWma3_Ok0jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PARTICLES = ['kaon'] # [\"pion\", 'kaon', \"muon\", \"proton\"]\n",
        "DROPOUTS = [0.25, 0.3, 0.35, 0.4]\n",
        "ENSEMBLES = [16, 32, 64, 128, 256]\n",
        "NUM_REPS = 10\n",
        "SUB_SAMPLE_SIZE = .3\n",
        "THRESHOLD = 1.0\n",
        "\n",
        "DATA_DIR = 'rich'\n",
        "CHECKPOINT_BASE = 'checkpoints'\n",
        "CKPT_NUMBER = 'ckpt-21'\n",
        "\n",
        "\n",
        "def get_checkpoint_name(particle):\n",
        "    return f'bernoulli_structured_dropout_line_test_cramer_weighted_{particle}'"
      ],
      "metadata": {
        "id": "E6kdyUS4dB53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _split_by_line(df, slope=1, intercept=0):\n",
        "    top_half = df[df['Brunel_ETA'] > df['Brunel_P'] * slope + intercept]\n",
        "    bottom_half = df[df['Brunel_ETA'] <= df['Brunel_P'] * slope + intercept]\n",
        "\n",
        "    top_half = top_half.reset_index(drop=True)\n",
        "    bottom_half = bottom_half.reset_index(drop=True)\n",
        "\n",
        "    return top_half, bottom_half\n",
        "\n",
        "\n",
        "def split_by_line(df_train, df_test):\n",
        "    return _split_by_line(df_train)[0], _split_by_line(df_test)[1]\n",
        "\n",
        "\n",
        "def load_particle_datasets(particle, data_dir=DATA_DIR):\n",
        "    \"\"\" The returned dictionary has this format:\n",
        "        {\n",
        "          \"<particle_name>\": {\n",
        "            'data_train': data_train,\n",
        "            'data_val': data_val,\n",
        "            'scaler': scaler,\n",
        "            'feats_train': feats_train,\n",
        "            'targets_train': targets_train,\n",
        "            'feats_val': feats_val,\n",
        "            'targets_val': targets_val\n",
        "          }\n",
        "        }\n",
        "    \"\"\"\n",
        "    data_train, data_val, scaler = get_merged_typed_dataset(data_dir, particle, dtype=np.float32, log=True,\n",
        "                                                            sample_fn=split_by_line)\n",
        "    feats_train, targets_train, _ = parse_dataset_np(data_train)\n",
        "    feats_val, targets_val, _ = parse_dataset_np(data_val)\n",
        "\n",
        "    print(f'feats_train shape\\t{feats_train.shape}\\n'\n",
        "          f'targets_train shape\\t{targets_train.shape}\\n'\n",
        "          f'feats_val shape  \\t{feats_val.shape}\\n'\n",
        "          f'targets_val shape\\t{targets_val.shape}\\n')\n",
        "\n",
        "    return {\n",
        "        'data_train': data_train,\n",
        "        'data_val': data_val,\n",
        "        'scaler': scaler,\n",
        "        'feats_train': feats_train,\n",
        "        'targets_train': targets_train,\n",
        "        'feats_val': feats_val,\n",
        "        'targets_val': targets_val\n",
        "    }\n",
        "\n",
        "datasets = {particle: load_particle_datasets(particle) for particle in PARTICLES}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zk-zDebdbfh",
        "outputId": "7a6b1ab8-5b27-4a0b-db30-350aaebc1e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and concatenating datasets:\n",
            "\trich/kaon2_+_up_2016_.csv\n",
            "\trich/kaon_+_up_2016_.csv\n",
            "\trich/kaon2_-_down_2016_.csv\n",
            "\trich/kaon_+_down_2016_.csv\n",
            "\trich/kaon2_+_down_2016_.csv\n",
            "\trich/kaon2_-_up_2016_.csv\n",
            "\trich/kaon_-_down_2016_.csv\n",
            "\trich/kaon_-_up_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 2000000\n",
            "scaler n_quantiles: 100000, time = 2.261545419692993\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(935276, 3)\n",
            "targets_train shape\t(935276, 5)\n",
            "feats_val shape  \t(532300, 3)\n",
            "targets_val shape\t(532300, 5)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MonteCarloDroupoutModel:\n",
        "    def __init__(self, particle, dropout_rate,\n",
        "                 log_dir='log_dir_tmp',\n",
        "                 checkpoint_dir=CHECKPOINT_BASE,\n",
        "                 debug=False):\n",
        "\n",
        "        self.particle = particle\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.log_dir = log_dir\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "\n",
        "        print(f'Generating model for {particle} with a dropout rate of {dropout_rate}')\n",
        "\n",
        "        self._gen_config = {\n",
        "            'drop_rate': dropout_rate,\n",
        "            'dropout_type': 'bernoulli',\n",
        "        }\n",
        "\n",
        "        self._generator = RichMCDropFunc(**self._gen_config)\n",
        "        self._generator.build((None, 3))\n",
        "        self._discriminator = RICHDiscriminator()\n",
        "\n",
        "        if debug:\n",
        "            print(\"\\nGenerator:\\n\")\n",
        "            print(self._generator.summary(line_length=96))\n",
        "            print(\"\\nDiscriminator:\\n\")\n",
        "            print(self._discriminator.summary())\n",
        "            print(f\"\\nCheckpoint path: {self.checkpoint_dir}\\n\")\n",
        "\n",
        "        # Model was trained with tensorflow 2.10.1, use the legacy optimizer\n",
        "        self._generator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
        "        self._discriminator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
        "\n",
        "        self._trainer_config = {\n",
        "            'generator': self._generator,\n",
        "            'discriminator': self._discriminator,\n",
        "            'generator_optimizer': self._generator_optimizer,\n",
        "            'discriminator_optimizer': self._discriminator_optimizer,\n",
        "            'checkpoint_dir': self.checkpoint_dir,\n",
        "            'log_dir': log_dir\n",
        "        }\n",
        "\n",
        "        trainer = CramerGANTrainer(**self._trainer_config)\n",
        "        # Restore pretrained model\n",
        "        trainer.restore_last()\n",
        "\n",
        "    def str(self):\n",
        "        return f\"{self.particle}_{self.dropout_rate}\"\n",
        "\n",
        "    def get_generator(self) -> VirtualEnsembleModel:\n",
        "        return self._generator"
      ],
      "metadata": {
        "id": "1rxa9QaXd6qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = MonteCarloDroupoutModel('kaon', 0.1, debug=True)\n",
        "gen1 = mc_model.get_generator()\n",
        "gen1.single_model_inference_mode()\n",
        "gen1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdyAQi-VeHHD",
        "outputId": "8585df04-23c6-4e67-be1d-ce949ff2b804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating model for kaon with a dropout rate of 0.1\n",
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "\n",
            "Generator:\n",
            "\n",
            "Model: \"virtual_ensemble_model\"\n",
            "________________________________________________________________________________________________\n",
            " Layer (type)                              Output Shape                          Param #        \n",
            "================================================================================================\n",
            " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
            "                                                                                                \n",
            " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
            "                                                                                                \n",
            " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
            "                                                                                                \n",
            " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " DensePrediction (Dense)                   (None, 5)                             645            \n",
            "                                                                                                \n",
            "================================================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Discriminator:\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8)                    0         ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 256)                  100224    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100224 (391.50 KB)\n",
            "Trainable params: 100224 (391.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Checkpoint path: checkpoints\n",
            "\n",
            "0.001\n",
            "Last ckpt:  None\n",
            "Model: \"virtual_ensemble_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Inputs (InputLayer)         [(None, 3)]               0         \n",
            "                                                                 \n",
            " NoiseInjection (NoiseInjec  (None, 67)                0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " Layer_0/Dense (Dense)       (None, 128)               8704      \n",
            "                                                                 \n",
            " Layer_0/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_0/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_1/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_1/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_1/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_2/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_2/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_2/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_3/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_3/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_3/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_4/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_4/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_4/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " DensePrediction (Dense)     (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generator(dropout_rate, dropout_type='bernoulli'):\n",
        "    gen_config = {\n",
        "        'drop_rate': dropout_rate,\n",
        "        'dropout_type': dropout_type,\n",
        "    }\n",
        "    generator = RichMCDropFunc(**gen_config)\n",
        "    generator.build((None, 3))\n",
        "    return generator"
      ],
      "metadata": {
        "id": "QkQtLhOsfm2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution to read embeddings of any layer:\n",
        "\n",
        "# 1. Create a new model with the same architecture\n",
        "new_gen = create_generator(0.1)\n",
        "new_gen.set_weights(gen1.get_weights())\n",
        "\n",
        "# 2. Create a new model that outputs from the layer of interest\n",
        "input_layer = new_gen.input\n",
        "output_layer = new_gen.layers[14].output  # Index is 14 because layer indexing starts from 0\n",
        "\n",
        "# 3. Create a `new_model` without optimizations\n",
        "new_model = Model(input_layer, [output_layer, new_gen.output])\n",
        "\n",
        "# 4. Use `new_model` to predict on any input vector and get the embeddings\n",
        "input_data = np.random.rand(1, 3)\n",
        "embedding, prediction = new_model.predict(input_data)\n",
        "\n",
        "print('Layer 4 embedding:', embedding)\n",
        "print('Final prediction:', prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f7964Nsfruv",
        "outputId": "5fa44697-7f9d-4697-b120-136d97348a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "1/1 [==============================] - 0s 252ms/step\n",
            "Layer 4 embedding: [[ 0.17052293 -0.2815201  -0.2520858  -0.15028125  0.22142968 -0.27584785\n",
            "  -0.5023401  -0.46137294 -0.3919465  -0.16284706 -0.51239127  0.12214717\n",
            "  -0.04213858  0.34308702 -0.04604173 -0.2288125  -0.29522505  0.15411066\n",
            "   0.51749533 -0.23563501  0.1944228   0.38582638  0.05307005 -0.28394228\n",
            "  -0.04318975 -0.0614185  -0.15341006 -0.26046407 -0.36376604 -0.14553931\n",
            "  -0.2214281   0.02179953 -0.19123876  0.03446744 -0.15266131 -0.00848499\n",
            "  -0.23002313 -0.23316294 -0.05080584  0.52292854 -0.00468181 -0.46704197\n",
            "   0.11049912 -0.3345214  -0.16706187  0.66778946 -0.11170307  0.10450091\n",
            "  -0.07133051 -0.7317531  -0.32408231  0.36991304 -0.17509575 -0.02209144\n",
            "  -0.10620698  0.29626992 -0.13980411  0.41269177 -0.10820699  0.26206267\n",
            "   0.01205708 -0.25190696 -0.48604205  0.0670359   0.71062285 -0.07978024\n",
            "  -0.20050943 -0.5262162  -0.15464188 -0.12407905 -0.43808293  0.24287237\n",
            "   0.14910167 -0.0853896  -0.33185694  0.14948821 -0.09187228 -0.06709661\n",
            "  -0.04426374 -0.5511508   0.37061495  0.2821642   0.05212671  0.3143712\n",
            "   0.16432162 -0.29970947  0.26242012 -0.44873166 -0.15557656  0.02358352\n",
            "   0.3178895  -0.14142287 -0.139088   -0.3003388  -0.20976552 -0.01313717\n",
            "   0.39741856 -0.43837416  0.12420687 -0.28753692  0.3630263  -0.02250405\n",
            "   0.06583293 -0.39428413 -0.02706265  0.16705036 -0.5217255   0.251715\n",
            "  -0.38464805 -0.1978006  -0.92087495  0.07899873 -0.44765225  0.20051351\n",
            "   0.30522418 -0.26112035  0.0227654  -0.0558989   0.11883841  0.03069855\n",
            "  -0.16826482 -0.33358833  0.23241627  0.09027076  0.37356246  0.25986308\n",
            "  -0.5461015   0.5302529 ]]\n",
            "Final prediction: [[-0.4837973   0.5681578   0.02648934  0.0217512  -0.26922262]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaon_train_feats = datasets['kaon']['feats_train']\n",
        "kaon_test_feats = datasets['kaon']['feats_val']\n",
        "kaon_test_targets = datasets['kaon']['targets_val']\n",
        "\n",
        "print('kaon train features shape:', kaon_train_feats.shape)\n",
        "print('kaon test features shape:', kaon_test_feats.shape)\n",
        "print('kaon test targets shape:', kaon_test_targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjt-dAjTieWX",
        "outputId": "ce353769-ac62-405c-cc6c-ace885211e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaon train features shape: (935276, 3)\n",
            "kaon test features shape: (532300, 3)\n",
            "kaon test targets shape: (532300, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaon_train_embeddings = new_model.predict(kaon_train_feats)[0]\n",
        "kaon_test_embeddings, kaon_test_predictions = new_model.predict(kaon_test_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqcVEKBEhqn7",
        "outputId": "3e689c27-f238-4c28-cb56-e641a8be1856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29228/29228 [==============================] - 78s 3ms/step\n",
            "16635/16635 [==============================] - 41s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'drive/MyDrive/Colab Notebooks/outputs/'\n",
        "\n",
        "np.save(dir + 'kaon_train_embeddings.npy', kaon_train_embeddings)\n",
        "np.save(dir + 'kaon_test_targets.npy', kaon_test_targets)\n",
        "np.save(dir + 'kaon_test_embeddings.npy', kaon_test_embeddings)\n",
        "np.save(dir + 'kaon_test_predictions.npy', kaon_test_predictions)"
      ],
      "metadata": {
        "id": "cgAgvraVi3zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}