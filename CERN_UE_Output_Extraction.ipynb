{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hFC265XMru8NyovZG-RP9zceMgI-172X",
      "authorship_tag": "ABX9TyNJs2GUayelPzzd3MVGfWmf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/uncertainty_gan/blob/main/CERN_UE_Output_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Vfsi-ed4caCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuSLTKXzcFiS",
        "outputId": "e01a462c-4008-4a8d-db6d-538ca1706103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lhcb-rich-gan-uncertainty'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Total 210 (delta 0), reused 0 (delta 0), pack-reused 210 (from 1)\u001b[K\n",
            "Receiving objects: 100% (210/210), 2.94 MiB | 14.55 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "mv: cannot move 'lhcb-rich-gan-uncertainty/experiments' to './experiments': Directory not empty\n",
            "mv: cannot move 'lhcb-rich-gan-uncertainty/src' to './src': Directory not empty\n",
            "rm: cannot remove 'sample_data/': No such file or directory\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
        "!mv lhcb-rich-gan-uncertainty/experiments .\n",
        "!mv lhcb-rich-gan-uncertainty/src .\n",
        "!rm -r lhcb-rich-gan-uncertainty/\n",
        "!rm -r sample_data/\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experiments.efficiency.uncertainty_model_train import train_model\n",
        "from experiments.efficiency.uncertainty_models import uncertainty_mlp\n",
        "from experiments.efficiency.uncertainty_utils import (\n",
        "    efficiency_bands_with_uncertainty, efficiency_momentum_with_uncertainty)\n",
        "from experiments.efficiency.utils import (\n",
        "    efficiency_bands, efficiency_momentum, ensemble_and_ref_model_inference,\n",
        "    ensemble_and_ref_model_inference_on_bands, tf_to_numpy_dataset,\n",
        "    threshold_selection)\n",
        "from src.cramer_gan_trainer import CramerGANTrainer\n",
        "from src.dataset import CramerGANDataset\n",
        "from src.datasets.utils_rich import (get_merged_typed_dataset,\n",
        "                                     parse_dataset_np, parse_example)\n",
        "from src.models.gans.discriminators.fcn_disc import RICHDiscriminator\n",
        "from src.models.gans.generators.fcn_gen import RichMCDropFunc, VirtualEnsembleModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4tFqIwachJ7",
        "outputId": "c6b5b7c4-5575-4ae6-8517-498d3cf82e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARTICLES = ['pion'] # [\"pion\", 'kaon', \"muon\", \"proton\"]\n",
        "DROPOUTS = [0.25, 0.3, 0.35, 0.4]\n",
        "ENSEMBLES = [16, 32, 64, 128, 256]\n",
        "NUM_REPS = 10\n",
        "SUB_SAMPLE_SIZE = .3\n",
        "THRESHOLD = 1.0\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/cern/data/rich'\n",
        "CHECKPOINT_BASE = '/content/drive/MyDrive/cern/checkpoints/'\n",
        "CKPT_NUMBER = 'ckpt-21'\n",
        "\n",
        "\n",
        "def get_checkpoint_name(particle):\n",
        "    return f'bernoulli_structured_dropout_line_test_cramer_weighted_{particle}'"
      ],
      "metadata": {
        "id": "E6kdyUS4dB53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _split_by_line(df, slope=1, intercept=0):\n",
        "    top_half = df[df['Brunel_ETA'] > df['Brunel_P'] * slope + intercept]\n",
        "    bottom_half = df[df['Brunel_ETA'] <= df['Brunel_P'] * slope + intercept]\n",
        "\n",
        "    top_half = top_half.reset_index(drop=True)\n",
        "    bottom_half = bottom_half.reset_index(drop=True)\n",
        "\n",
        "    return top_half, bottom_half\n",
        "\n",
        "\n",
        "def split_by_line(df_train, df_test):\n",
        "    return _split_by_line(df_train)[0], _split_by_line(df_test)[1]\n",
        "\n",
        "\n",
        "def load_particle_datasets(particle, data_dir=DATA_DIR):\n",
        "    \"\"\" The returned dictionary has this format:\n",
        "        {\n",
        "          \"<particle_name>\": {\n",
        "            'data_train': data_train,\n",
        "            'data_val': data_val,\n",
        "            'scaler': scaler,\n",
        "            'feats_train': feats_train,\n",
        "            'targets_train': targets_train,\n",
        "            'feats_val': feats_val,\n",
        "            'targets_val': targets_val\n",
        "          }\n",
        "        }\n",
        "    \"\"\"\n",
        "    data_train, data_val, scaler = get_merged_typed_dataset(data_dir, particle, dtype=np.float32, log=True,\n",
        "                                                            sample_fn=split_by_line)\n",
        "    feats_train, targets_train, _ = parse_dataset_np(data_train)\n",
        "    feats_val, targets_val, _ = parse_dataset_np(data_val)\n",
        "\n",
        "    print(f'feats_train shape\\t{feats_train.shape}\\n'\n",
        "          f'targets_train shape\\t{targets_train.shape}\\n'\n",
        "          f'feats_val shape  \\t{feats_val.shape}\\n'\n",
        "          f'targets_val shape\\t{targets_val.shape}\\n')\n",
        "\n",
        "    return {\n",
        "        'data_train': data_train,\n",
        "        'data_val': data_val,\n",
        "        'scaler': scaler,\n",
        "        'feats_train': feats_train,\n",
        "        'targets_train': targets_train,\n",
        "        'feats_val': feats_val,\n",
        "        'targets_val': targets_val\n",
        "    }\n",
        "\n",
        "datasets = {particle: load_particle_datasets(particle) for particle in PARTICLES}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zk-zDebdbfh",
        "outputId": "4656a9bf-07a8-471d-db54-aba71517439e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and concatenating datasets:\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion_-_up_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion_+_up_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion2_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion2_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion2_-_up_2016_.csv\n",
            "\t/content/drive/MyDrive/cern/data/rich/pion2_+_up_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 2000000\n",
            "scaler n_quantiles: 100000, time = 2.965564250946045\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(947947, 3)\n",
            "targets_train shape\t(947947, 5)\n",
            "feats_val shape  \t(524521, 3)\n",
            "targets_val shape\t(524521, 5)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MonteCarloDroupoutModel:\n",
        "    def __init__(self, particle, dropout_rate,\n",
        "                 log_dir='log_dir_tmp',\n",
        "                 checkpoint_base=CHECKPOINT_BASE,\n",
        "                 chekpoint_file=CKPT_NUMBER,\n",
        "                 debug=False):\n",
        "        self.particle = particle\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.log_dir = log_dir\n",
        "\n",
        "        print(f'Generating model for {particle} with a dropout rate of {dropout_rate}')\n",
        "\n",
        "        self._gen_config = {\n",
        "            'drop_rate': dropout_rate,\n",
        "            'dropout_type': 'bernoulli',\n",
        "        }\n",
        "\n",
        "        self._generator = RichMCDropFunc(**self._gen_config)\n",
        "        self._generator.build((None, 3))\n",
        "        self._discriminator = RICHDiscriminator()\n",
        "\n",
        "        self._checkpoint_dir = os.path.join(checkpoint_base, get_checkpoint_name(self.particle))\n",
        "        self._filename = os.path.join(self._checkpoint_dir, chekpoint_file)\n",
        "\n",
        "        if debug:\n",
        "            print(\"\\nGenerator:\\n\")\n",
        "            print(self._generator.summary(line_length=96))\n",
        "            print(\"\\nDiscriminator:\\n\")\n",
        "            print(self._discriminator.summary())\n",
        "            print(f\"\\nCheckpoint filename: {self._filename}\\n\")\n",
        "\n",
        "        # Model was trained with tensorflow 2.10.1, use the legacy optimizer\n",
        "        self._generator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
        "        self._discriminator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
        "\n",
        "        self._trainer_config = {\n",
        "            'generator': self._generator,\n",
        "            'discriminator': self._discriminator,\n",
        "            'generator_optimizer': self._generator_optimizer,\n",
        "            'discriminator_optimizer': self._discriminator_optimizer,\n",
        "            'checkpoint_dir': self._checkpoint_dir,\n",
        "            'log_dir': log_dir\n",
        "        }\n",
        "        trainer = CramerGANTrainer(**self._trainer_config)\n",
        "        # Restore pretrained model\n",
        "        trainer.restore(self._filename)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.particle}_{self.dropout_rate}\"\n",
        "\n",
        "    def get_generator(self) -> VirtualEnsembleModel:\n",
        "        return self._generator"
      ],
      "metadata": {
        "id": "1rxa9QaXd6qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = MonteCarloDroupoutModel('pion', 0.1, debug=True)\n",
        "gen1 = mc_model.get_generator()\n",
        "gen1.single_model_inference_mode()\n",
        "gen1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdyAQi-VeHHD",
        "outputId": "73ab7c79-a0f6-4a99-85a7-1bb651636677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating model for pion with a dropout rate of 0.1\n",
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "\n",
            "Generator:\n",
            "\n",
            "Model: \"virtual_ensemble_model\"\n",
            "________________________________________________________________________________________________\n",
            " Layer (type)                              Output Shape                          Param #        \n",
            "================================================================================================\n",
            " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
            "                                                                                                \n",
            " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
            "                                                                                                \n",
            " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
            "                                                                                                \n",
            " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " DensePrediction (Dense)                   (None, 5)                             645            \n",
            "                                                                                                \n",
            "================================================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Discriminator:\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8)                    0         ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 256)                  100224    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100224 (391.50 KB)\n",
            "Trainable params: 100224 (391.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Checkpoint filename: /content/drive/MyDrive/cern/checkpoints/bernoulli_structured_dropout_line_test_cramer_weighted_pion/ckpt-21\n",
            "\n",
            "0.001\n",
            "Model: \"virtual_ensemble_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Inputs (InputLayer)         [(None, 3)]               0         \n",
            "                                                                 \n",
            " NoiseInjection (NoiseInjec  (None, 67)                0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " Layer_0/Dense (Dense)       (None, 128)               8704      \n",
            "                                                                 \n",
            " Layer_0/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_0/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_1/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_1/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_1/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_2/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_2/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_2/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_3/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_3/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_3/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_4/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_4/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_4/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " DensePrediction (Dense)     (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generator(dropout_rate, dropout_type='bernoulli'):\n",
        "    gen_config = {\n",
        "        'drop_rate': dropout_rate,\n",
        "        'dropout_type': dropout_type,\n",
        "    }\n",
        "    generator = RichMCDropFunc(**gen_config)\n",
        "    generator.build((None, 3))\n",
        "    return generator"
      ],
      "metadata": {
        "id": "QkQtLhOsfm2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution to read embeddings of any layer:\n",
        "\n",
        "# 1. Create a new model with the same architecture\n",
        "new_gen = create_generator(0.1)\n",
        "new_gen.set_weights(gen1.get_weights())\n",
        "\n",
        "# 2. Create a new model that outputs from the layer of interest\n",
        "input_layer = new_gen.input\n",
        "output_layer = new_gen.layers[14].output  # Index is 14 because layer indexing starts from 0\n",
        "\n",
        "# 3. Create a `new_model` without optimizations\n",
        "new_model = Model(input_layer, [output_layer, new_gen.output])\n",
        "\n",
        "# 4. Use `new_model` to predict on any input vector and get the embeddings\n",
        "input_data = np.random.rand(1, 3)\n",
        "embedding, prediction = new_model.predict(input_data)\n",
        "\n",
        "print('Layer 4 embedding:', embedding)\n",
        "print('Final prediction:', prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f7964Nsfruv",
        "outputId": "c1b5d3fd-1df0-4d42-d32e-dc09ef29af5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "1/1 [==============================] - 0s 313ms/step\n",
            "Layer 4 embedding: [[-0.13039863  0.07018615 -0.58620447  0.27404422 -0.5218892  -0.42251518\n",
            "   0.1326365  -0.12117149 -0.6466348  -0.17054203 -0.03501824  0.40272358\n",
            "  -0.3218141  -0.6264842   0.31098336  0.040048   -0.18954287  0.13452604\n",
            "  -0.60610276  0.07645752 -0.49973622  0.18829209 -0.43715978 -0.03523372\n",
            "  -0.61529243 -0.31356004 -0.1505895  -0.31181842  0.09629247 -0.24686044\n",
            "  -0.5043816   0.06503329 -0.09505799 -0.5476164   0.04736098  0.4509455\n",
            "  -0.56498504 -0.5798478  -0.540283    0.23396093  0.4231578   0.41542488\n",
            "  -0.5008768   0.07033277  0.19642603  0.3640912   0.2949308   0.05807041\n",
            "   0.14231616 -0.5481269   0.26094338 -0.37120897 -0.31159335  0.09640955\n",
            "   0.4567487   0.48678613  0.3774986  -0.5941418   0.07282819 -0.14715923\n",
            "  -0.21480635  0.6845972   0.10156496  0.72645295 -0.14876929 -0.23596102\n",
            "   0.655008    0.26153165 -0.18069889  0.07549362  0.15985073 -0.4726729\n",
            "   0.267219   -0.06900786  0.06351279  0.34687132  0.06621654 -0.10366043\n",
            "  -0.88998324 -0.40734398  0.3913923   0.14833331 -0.9604948   0.13125366\n",
            "   0.19005096  0.19946282 -0.62064254 -0.7696881   0.05896823 -0.98281837\n",
            "  -0.04067852 -0.00780139 -0.04441503  0.3745877   0.32155934 -0.3005828\n",
            "  -0.17648569  0.38307297 -0.24751176 -0.10395804 -0.4322852  -0.42184618\n",
            "   0.37640744  0.23675433 -0.13233258  0.02135759 -0.47559792 -0.15611555\n",
            "   0.08800872 -0.17759617  0.39913356  0.23387717 -0.23169573 -0.22044961\n",
            "   0.08494873 -0.08576874 -0.63576055 -0.50836945 -0.51281416  0.29380915\n",
            "   0.8256774  -0.03773433 -0.71448916 -0.14298302 -0.4082876  -0.73108524\n",
            "  -0.29661167 -0.16300406]]\n",
            "Final prediction: [[ 0.44737163 -0.18334375  0.94848883  0.37911642  0.34277862]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pion_test_feats = datasets['pion']['feats_val']\n",
        "pion_test_targets = datasets['pion']['targets_val']\n",
        "\n",
        "print('Pion test features shape:', pion_test_feats.shape)\n",
        "print('Pion test targets shape:', pion_test_targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjt-dAjTieWX",
        "outputId": "c8f9b6e7-e1ae-40a8-dd4f-919f92bc06a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pion test features shape: (524521, 3)\n",
            "Pion test targets shape: (524521, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pion_embeddings, pion_predictions = new_model.predict(pion_test_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqcVEKBEhqn7",
        "outputId": "6fcc6752-2692-4b8f-acb9-63e43157968f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16392/16392 [==============================] - 42s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'drive/MyDrive/Colab Notebooks/outputs/'\n",
        "\n",
        "np.save(dir + 'pion_targets.npy', pion_test_targets)\n",
        "np.save(dir + 'pion_embeddings.npy', pion_embeddings)\n",
        "np.save(dir + 'pion_predictions.npy', pion_predictions)"
      ],
      "metadata": {
        "id": "cgAgvraVi3zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}