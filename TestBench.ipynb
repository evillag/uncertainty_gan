{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d97ed95",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/evillag/uncertainty_gan/blob/main/test_bench/TestBench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "id": "8953bf4723cb4b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8953bf4723cb4b5",
    "outputId": "d255de5f-e951-498f-abb9-fcd48df26972",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:34.300751Z",
     "start_time": "2024-06-08T22:26:34.240988Z"
    }
   },
   "source": [
    "IN_COLAB = True\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  # Using Google Drive\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "  !git clone https://github.com/evillag/uncertainty_gan.git\n",
    "  !mv uncertainty_gan/mcd .\n",
    "  !mv uncertainty_gan/feature_densities .\n",
    "  !mv uncertainty_gan/test_bench .\n",
    "  %rm -rf uncertainty_gan/\n",
    "\n",
    "  !git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
    "  !mv lhcb-rich-gan-uncertainty/experiments .\n",
    "  !mv lhcb-rich-gan-uncertainty/src .\n",
    "  %rm -rf lhcb-rich-gan-uncertainty/\n",
    "  %rm -rf sample_data/\n",
    "  %pip install tensorflow-addons\n",
    "\n",
    "  # Dataset download and extraction\n",
    "  !unzip -qq drive/MyDrive/cern/data/rich.zip\n",
    "\n",
    "  # Model checkpoint download and extraction\n",
    "  !unzip -qq drive/MyDrive/cern/data/checkpoints_dropout_0.01.zip\n",
    "\n",
    "  # Model embeddings download and extraction\n",
    "  !unzip -qq drive/MyDrive/cern/data/embeddings.zip\n",
    "\n",
    "  # Results folder creation\n",
    "  !mkdir /content/drive/MyDrive/cern/data/results\n",
    "\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "print(f'IN_COLAB: {IN_COLAB}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_COLAB: False\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:37.412940Z",
     "start_time": "2024-06-08T22:26:34.302750Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "if not IN_COLAB:\n",
    "  import os\n",
    "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "  # Ask Tensorflow to use GPU memory judiciously on single GPU system\n",
    "  physical_devices = tf.config.list_physical_devices('GPU')  \n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from test_bench import get_checkpoint_name, load_particle_datasets, subsample_dataset\n",
    "from test_bench.model import MonteCarloDropoutModel\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b537f49152f44ec8",
   "metadata": {
    "id": "b537f49152f44ec8"
   },
   "source": [
    "# Test Bench for the Monte Carlo Dropout and Feature Density methods\n",
    "\n",
    "1. Select sample data\n",
    "2. Create a model\n",
    "3. Generate a single target with single inference mode\n",
    "4. Estimate MCD uncertainty\n",
    "5. Estimate FD uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "id": "754279944432b7f1",
   "metadata": {
    "id": "754279944432b7f1",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:37.428940Z",
     "start_time": "2024-06-08T22:26:37.413940Z"
    }
   },
   "source": [
    "# Parameters\n",
    "PARTICLE = 'proton'\n",
    "CHECKPOINT_DP = 0.0001\n",
    "DROPOUT_TYPE = 'bernoulli_structured'\n",
    "CHECKPOINT_BASE = 'checkpoints/'\n",
    "DATA_DIR = 'rich/'\n",
    "SUB_SAMPLE_PERCENT = 0.0001\n",
    "\n",
    "# MCD parameters\n",
    "MCD_ENSEMBLE_SIZE = 300\n",
    "\n",
    "# FD parameters\n",
    "embeddings_dir = f'embeddings/'\n",
    "\n",
    "# Save results path\n",
    "output_dir = 'results/'\n",
    "if IN_COLAB:\n",
    "  output_dir = f'/content/drive/MyDrive/cern/data/{output_dir}'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "707cd509ae0c649a",
   "metadata": {
    "id": "707cd509ae0c649a"
   },
   "source": [
    "# Load data and Sample selection"
   ]
  },
  {
   "cell_type": "code",
   "id": "73e7b604fa3d2457",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73e7b604fa3d2457",
    "outputId": "15f39f8b-d0db-4e2f-9657-1a88b968fdc9",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:45.932843Z",
     "start_time": "2024-06-08T22:26:37.430942Z"
    }
   },
   "source": [
    "dataset = load_particle_datasets(PARTICLE, DATA_DIR)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and concatenating datasets:\n",
      "\trich\\proton_+_down_2016_.csv\n",
      "\trich\\proton_+_up_2016_.csv\n",
      "\trich\\proton_-_down_2016_.csv\n",
      "\trich\\proton_-_up_2016_.csv\n",
      "splitting to train/val/test\n",
      "fitting the scaler\n",
      "scaler train sample size: 1000000\n",
      "scaler n_quantiles: 100000, time = 0.7408425807952881\n",
      "scaling train set\n",
      "scaling test set\n",
      "converting dtype to <class 'numpy.float32'>\n",
      "feats_train shape\t(454724, 3)\n",
      "targets_train shape\t(454724, 5)\n",
      "feats_val shape  \t(272832, 3)\n",
      "targets_val shape\t(272832, 5)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "31d95808b32bac06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31d95808b32bac06",
    "outputId": "479138d2-86bd-4a73-8b3c-a2d5340bb432",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:46.076354Z",
     "start_time": "2024-06-08T22:26:45.933848Z"
    }
   },
   "source": [
    "# Draw a sample of the datasets\n",
    "x_sample, y_sample = subsample_dataset(dataset['feats_val'], dataset['targets_val'], SUB_SAMPLE_PERCENT)\n",
    "x_sample.shape, y_sample.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([27, 3]), TensorShape([27, 5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "605b58c1e3fc7f9",
   "metadata": {
    "id": "605b58c1e3fc7f9"
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "id": "74ff0b59fb3a914d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74ff0b59fb3a914d",
    "outputId": "55f64de8-e940-4f58-f34c-3888e65d6bd1",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:46.557850Z",
     "start_time": "2024-06-08T22:26:46.078356Z"
    }
   },
   "source": [
    "model = MonteCarloDropoutModel(\n",
    "    PARTICLE,\n",
    "    dropout_rate=CHECKPOINT_DP,\n",
    "    checkpoint_dir=CHECKPOINT_BASE + get_checkpoint_name(PARTICLE, CHECKPOINT_DP, DROPOUT_TYPE),\n",
    "    debug=True\n",
    ")\n",
    "generator = model.get_generator()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating model for proton with a dropout rate of 0.0001\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "\n",
      "Generator:\n",
      "\n",
      "Model: \"virtual_ensemble_model\"\n",
      "________________________________________________________________________________________________\n",
      " Layer (type)                              Output Shape                          Param #        \n",
      "================================================================================================\n",
      " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
      "                                                                                                \n",
      " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
      "                                                                                                \n",
      " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
      "                                                                                                \n",
      " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " DensePrediction (Dense)                   (None, 5)                             645            \n",
      "                                                                                                \n",
      "================================================================================================\n",
      "Total params: 75,397\n",
      "Trainable params: 75,397\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Discriminator:\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8)            0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 256)          100224      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100,224\n",
      "Trainable params: 100,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Checkpoint path: checkpoints/bernoulli_structured_dropout_line_test_cramer_drop_rate_0.0001_proton\n",
      "\n",
      "0.001\n",
      "Last ckpt:  None\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "97d6eaa45996218e",
   "metadata": {
    "id": "97d6eaa45996218e"
   },
   "source": [
    "## Single model prediction"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6fb303dc66f661b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6fb303dc66f661b",
    "outputId": "f9371cc8-988f-4230-a0c0-9f11d003fda8",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:46.917567Z",
     "start_time": "2024-06-08T22:26:46.558852Z"
    }
   },
   "source": [
    "generator.single_model_inference_mode()\n",
    "t_generated = generator.predict(x_sample)\n",
    "\n",
    "print('Generated target:')\n",
    "print(t_generated)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 318ms/step\n",
      "Generated target:\n",
      "[[-0.08103226 -0.12261854 -0.04804504  0.09772559  0.01369808]\n",
      " [-0.23752145 -0.1427123  -0.13845053 -0.03081239  0.11991075]\n",
      " [-0.35803813 -0.17356156 -0.1939515   0.27882186  0.10709971]\n",
      " [-0.1406405  -0.0327857   0.06726847  0.26267052  0.0725523 ]\n",
      " [-0.29181573 -0.18854555  0.04417044  0.17666477 -0.03244647]\n",
      " [-0.14478582 -0.11270503 -0.12632048  0.03210034  0.01816113]\n",
      " [-0.16994928 -0.11837488 -0.04517685 -0.01940154  0.03906797]\n",
      " [-0.3155026  -0.06509914  0.07237132  0.26501042  0.06209607]\n",
      " [-0.13202992 -0.17113003  0.03348824  0.17486927 -0.01286009]\n",
      " [-0.04872167 -0.1624827  -0.0034431   0.11652523 -0.12475193]\n",
      " [-0.12677765 -0.05199048  0.06095138 -0.03762685 -0.02320172]\n",
      " [-0.2569429  -0.10069627 -0.0960131   0.02658819  0.0396785 ]\n",
      " [-0.20108688 -0.05038339 -0.08040392 -0.02623529 -0.01493893]\n",
      " [-0.3254113  -0.1230049  -0.01371121  0.16174427 -0.01058929]\n",
      " [-0.09570699 -0.1695442  -0.0006408   0.08017218  0.07097784]\n",
      " [-0.16890696 -0.087522   -0.06962632 -0.04611266  0.12097964]\n",
      " [-0.20179904  0.02572352 -0.10484674  0.17554927  0.02332908]\n",
      " [-0.25174588 -0.13792337 -0.2391775   0.08970618 -0.01204982]\n",
      " [-0.07383391 -0.10092855 -0.0769242  -0.15595654  0.12980077]\n",
      " [-0.1706759  -0.23023453 -0.04119772  0.06199054  0.1972025 ]\n",
      " [-0.17961441 -0.11076031  0.1517589  -0.09652136  0.18898155]\n",
      " [-0.07496527 -0.06832448 -0.008649    0.06760829  0.09080897]\n",
      " [-0.11229149 -0.24378347 -0.13856786  0.02647298  0.05712549]\n",
      " [-0.3422754  -0.09514765 -0.11219108  0.13657859 -0.03327093]\n",
      " [-0.05110269 -0.1092883   0.00719236  0.02570318 -0.01747766]\n",
      " [-0.25220132 -0.13143912 -0.06735689 -0.14572597  0.16456863]\n",
      " [-0.16864039 -0.20071265  0.01342673  0.11541223  0.03680752]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Euclidean distance between real and generated targets",
   "id": "6472950f982264fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:46.932566Z",
     "start_time": "2024-06-08T22:26:46.918568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "real_target = tf.constant(y_sample)\n",
    "generated_target = tf.constant(t_generated)\n",
    "\n",
    "# Compute the Euclidean distance (L2 norm) between real and generated\n",
    "distance_single_pred = tf.norm(real_target - generated_target, axis=1)\n",
    "print('Euclidean distance (L2 norm) between real and generated targets:')\n",
    "print(distance_single_pred)"
   ],
   "id": "27f4ccb1adfa0ca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance (L2 norm) between real and generated targets:\n",
      "tf.Tensor(\n",
      "[1.0750118  1.5217443  2.343853   2.7050796  1.4576181  3.4827523\n",
      " 1.5568006  1.415955   0.99176174 1.3966324  0.9213318  3.766989\n",
      " 1.1762645  1.3272269  2.535774   2.375632   1.7997671  2.2176425\n",
      " 3.6968408  2.3918388  1.6772178  1.7729249  1.1383957  0.89883566\n",
      " 1.3817779  2.5438013  1.2953957 ], shape=(27,), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:46.948292Z",
     "start_time": "2024-06-08T22:26:46.933569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save real and generated targets\n",
    "np.save(output_dir + f'{PARTICLE}_t_generated.npy', t_generated)\n",
    "np.save(output_dir + f'{PARTICLE}_y_real.npy', y_sample)"
   ],
   "id": "JpMqFDki0rkw",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "121c68a8bd902eea",
   "metadata": {
    "id": "121c68a8bd902eea"
   },
   "source": [
    "## Monte Carlo Dropout method"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c719499767f5934",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c719499767f5934",
    "outputId": "b02c7e9c-e6f5-4981-aed5-42cd509508fc",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:51.968673Z",
     "start_time": "2024-06-08T22:26:46.949589Z"
    }
   },
   "source": [
    "from mcd.MCDEvaluator import MCDEvaluator\n",
    "\n",
    "mcd_evaluator = MCDEvaluator(model, MCD_ENSEMBLE_SIZE)\n",
    "mcd_uncertainty, _ = mcd_evaluator.evaluate(x_sample)\n",
    "mcd_uncertainty\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ensemble(300) predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 60.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27, 5), dtype=float32, numpy=\n",
       "array([[0.01076716, 0.01232317, 0.00806856, 0.00986874, 0.00755464],\n",
       "       [0.01440388, 0.01194277, 0.00957286, 0.010514  , 0.00940598],\n",
       "       [0.01395028, 0.01180591, 0.0098174 , 0.0110699 , 0.00786071],\n",
       "       [0.011423  , 0.01100715, 0.00773758, 0.00872663, 0.00626604],\n",
       "       [0.01069109, 0.01177249, 0.00697898, 0.00870381, 0.00698918],\n",
       "       [0.01283105, 0.01293545, 0.00773827, 0.01318455, 0.00818158],\n",
       "       [0.01211472, 0.01275276, 0.00991683, 0.01055802, 0.00782606],\n",
       "       [0.01179581, 0.01249789, 0.00789643, 0.0093854 , 0.008521  ],\n",
       "       [0.01006566, 0.01166148, 0.00705296, 0.00979996, 0.00692104],\n",
       "       [0.01297649, 0.01212419, 0.00830741, 0.00867565, 0.00822749],\n",
       "       [0.01147509, 0.01327143, 0.0081468 , 0.01220207, 0.0092034 ],\n",
       "       [0.01256346, 0.01391346, 0.00856029, 0.00957174, 0.00809941],\n",
       "       [0.01276435, 0.01139864, 0.00766933, 0.01036213, 0.00775571],\n",
       "       [0.01123512, 0.01141803, 0.00703333, 0.00969511, 0.00938686],\n",
       "       [0.01119686, 0.01367056, 0.00697535, 0.00976199, 0.00894606],\n",
       "       [0.01258964, 0.01092255, 0.00737651, 0.0115021 , 0.00987749],\n",
       "       [0.0107246 , 0.00982447, 0.00727235, 0.00725253, 0.00648831],\n",
       "       [0.01465284, 0.01436383, 0.00667724, 0.01159087, 0.00869383],\n",
       "       [0.01052717, 0.00893216, 0.00749647, 0.01057681, 0.00839254],\n",
       "       [0.0112104 , 0.01213921, 0.0079513 , 0.00973996, 0.0075596 ],\n",
       "       [0.00950296, 0.01400855, 0.0073637 , 0.00833548, 0.00672471],\n",
       "       [0.01062707, 0.00977435, 0.00720776, 0.00833221, 0.00793749],\n",
       "       [0.01191929, 0.01399041, 0.00890812, 0.01298003, 0.01041215],\n",
       "       [0.01012067, 0.01080266, 0.00661588, 0.00840639, 0.00681221],\n",
       "       [0.01252407, 0.0122745 , 0.00728937, 0.01011434, 0.01059615],\n",
       "       [0.01250408, 0.01369661, 0.00845727, 0.01269644, 0.01043268],\n",
       "       [0.01141763, 0.01086205, 0.00744223, 0.00917867, 0.00796077]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "363e0d79eb84e9fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "363e0d79eb84e9fa",
    "outputId": "a5923f98-e252-4f19-b9a6-314f78c92151",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:51.983957Z",
     "start_time": "2024-06-08T22:26:51.969675Z"
    }
   },
   "source": [
    "mcd_uncertainty.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([27, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "Vs1mp9kZ1d4u",
   "metadata": {
    "id": "Vs1mp9kZ1d4u",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:51.999489Z",
     "start_time": "2024-06-08T22:26:51.984974Z"
    }
   },
   "source": [
    "# Save MCD uncertainties\n",
    "np.save(output_dir + f'{PARTICLE}_mcd_uncertainty.npy', mcd_uncertainty)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "d7e2a5f809e9e7f1",
   "metadata": {
    "id": "d7e2a5f809e9e7f1"
   },
   "source": [
    "## Feature Densities method"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:26:52.075027Z",
     "start_time": "2024-06-08T22:26:52.000493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from feature_densities.feature_density_evaluator import FeatureDensityEvaluator\n",
    "\n",
    "train_embeddings = np.load(embeddings_dir + f'{PARTICLE}_train_embeddings.npy')\n",
    "print(train_embeddings.shape)"
   ],
   "id": "55b16e4c20270a6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454724, 128)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f5e680e33c07c6bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5e680e33c07c6bd",
    "outputId": "8cfd3c28-dbfc-4b8f-9eb5-e7b8b270f51d",
    "ExecuteTime": {
     "end_time": "2024-06-08T22:06:45.256095Z",
     "start_time": "2024-06-08T22:06:44.030022Z"
    }
   },
   "source": [
    "fd_evaluator = FeatureDensityEvaluator(\n",
    "  model, train_embeddings, likelihood_method='integration', use_tf_version=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454724, 128)\n",
      "Generating an embeddings model\n",
      "Fitting KDE functions to known embeddings\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:48:20.810475Z",
     "start_time": "2024-06-08T21:46:35.578050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fd_uncertainty_integration, _ = fd_evaluator.evaluate(x_sample)\n",
    "\n",
    "print('Feature Densities using INTEGRATION uncertainty score for x_sample:')\n",
    "fd_uncertainty_integration"
   ],
   "id": "2e291451fbae78cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sample´s embeddings\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Estimating sample´s feature densities\n",
      "Calculating likelihoods with integration method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:45<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Densities using INTEGRATION uncertainty score for x_sample:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27,), dtype=float32, numpy=\n",
       "array([0.97046876, 0.9696325 , 0.97154456, 0.96630245, 0.97286636,\n",
       "       0.9746166 , 0.96553075, 0.9684683 , 0.9654089 , 0.97142977,\n",
       "       0.96899945, 0.9692397 , 0.9694347 , 0.9637549 , 0.97479284,\n",
       "       0.96872807, 0.9693329 , 0.9683467 , 0.96955067, 0.9686049 ,\n",
       "       0.970806  , 0.97706944, 0.96915203, 0.9695235 , 0.9700593 ,\n",
       "       0.97384274, 0.9706849 ], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "zONmkpvs1rMd",
   "metadata": {
    "id": "zONmkpvs1rMd",
    "ExecuteTime": {
     "end_time": "2024-06-08T21:48:57.713002Z",
     "start_time": "2024-06-08T21:48:57.705001Z"
    }
   },
   "source": [
    "# Save FD uncertainties with integration\n",
    "np.save(output_dir + f'{PARTICLE}_fd_uncertainty_integration.npy', fd_uncertainty_integration)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test with a training sample ",
   "id": "aa23690a916c8f65"
  },
  {
   "cell_type": "code",
   "id": "a82d9b57-e49f-45d1-b388-26e573cc0de8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5e680e33c07c6bd",
    "outputId": "8cfd3c28-dbfc-4b8f-9eb5-e7b8b270f51d",
    "ExecuteTime": {
     "end_time": "2024-06-08T21:14:19.343549Z",
     "start_time": "2024-06-08T21:11:19.953739Z"
    }
   },
   "source": [
    "x_sample_train, y_sample_train = subsample_dataset(dataset['feats_train'], dataset['targets_train'], SUB_SAMPLE_PERCENT)\n",
    "\n",
    "fd_uncertainty_integration_x_sample_train, _ = fd_evaluator.evaluate(x_sample_train)\n",
    "\n",
    "print('Feature Densities using INTEGRATION uncertainty score for x_sample_train:')\n",
    "fd_uncertainty_integration_x_sample_train"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KDE functions to known embeddings\n",
      "Calculating sample´s embeddings\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Estimating sample´s feature densities\n",
      "Calculating likelihoods with integration method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [02:58<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Densities using INTEGRATION uncertainty score for x_sample_train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
       "array([0.9619562 , 0.96834004, 0.9704213 , 0.9669212 , 0.96809244,\n",
       "       0.95906466, 0.9657856 , 0.96944016, 0.9678844 , 0.97052383,\n",
       "       0.96470207, 0.9690555 , 0.9670368 , 0.9726632 , 0.9664482 ,\n",
       "       0.9681256 , 0.96320534, 0.9627804 , 0.97448444, 0.97457176,\n",
       "       0.9735359 , 0.9690675 , 0.9704136 , 0.96173954, 0.95964956,\n",
       "       0.9675619 , 0.96438915, 0.9686352 , 0.9587869 , 0.9691076 ,\n",
       "       0.9699587 , 0.9688715 , 0.9619854 , 0.96912503, 0.97349656,\n",
       "       0.9660821 , 0.9749091 , 0.9677489 , 0.9679755 , 0.97203887,\n",
       "       0.9651049 , 0.9608933 , 0.96106386, 0.9678883 , 0.9695483 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### FD uncertainty estimation using normalized likelihood",
   "id": "ee7937aa2416a876"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:28:21.608179Z",
     "start_time": "2024-06-08T22:27:07.241559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fd_evaluator_normalized = FeatureDensityEvaluator(\n",
    "  model, train_embeddings, use_tf_version=True, likelihood_method='normalized')\n",
    "\n",
    "fd_uncertainty_normalized, _ = fd_evaluator_normalized.evaluate(x_sample)\n",
    "\n",
    "print('Feature Densities using NORMALIZED uncertainty score for x_sample:')\n",
    "fd_uncertainty_normalized"
   ],
   "id": "8708230d258d1631",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating an embeddings model\n",
      "Fitting KDE functions to known embeddings\n",
      "Calculating sample´s embeddings\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "Estimating sample´s feature densities\n",
      "Calculating normalized likelihoods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [01:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m fd_evaluator_normalized \u001B[38;5;241m=\u001B[39m FeatureDensityEvaluator(\n\u001B[0;32m      2\u001B[0m   model, train_embeddings, use_tf_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, likelihood_method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnormalized\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m fd_uncertainty_normalized, _ \u001B[38;5;241m=\u001B[39m \u001B[43mfd_evaluator_normalized\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_sample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeature Densities using NORMALIZED uncertainty score for x_sample:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m fd_uncertainty_normalized\n",
      "File \u001B[1;32mD:\\src\\maestria\\cern\\uncertainty_gan\\feature_densities\\feature_density_evaluator.py:186\u001B[0m, in \u001B[0;36mFeatureDensityEvaluator.evaluate\u001B[1;34m(self, x_sample)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_sample):\n\u001B[1;32m--> 186\u001B[0m     uncertainties, generated_targets \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkde_fit_functions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlikelihood_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_tf_version\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalization_datapoints\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m uncertainties, generated_targets\n",
      "File \u001B[1;32mD:\\src\\maestria\\cern\\uncertainty_gan\\feature_densities\\feature_density_evaluator.py:162\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(model, x_sample, kde_fit_functions, likelihood_method, embeddings_model, use_tf_version, normalization_datapoints)\u001B[0m\n\u001B[0;32m    160\u001B[0m     feature_densities \u001B[38;5;241m=\u001B[39m integration_fn(sample_embeddings, kde_fit_functions)\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m likelihood_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnormalized\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 162\u001B[0m     feature_densities \u001B[38;5;241m=\u001B[39m \u001B[43mnormalized_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkde_fit_functions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalization_datapoints\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m reduced_feature_densities \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mreduce_mean(feature_densities, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m reduced_feature_densities, sample_predictions\n",
      "File \u001B[1;32mD:\\src\\maestria\\cern\\uncertainty_gan\\feature_densities\\feature_density_evaluator.py:89\u001B[0m, in \u001B[0;36mtf_calculate_normalized_likelihoods\u001B[1;34m(embeddings, kde_fit_functions, normalization_datapoints)\u001B[0m\n\u001B[0;32m     86\u001B[0m         row, fit_max \u001B[38;5;241m=\u001B[39m row_and_kde_max\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m kde_fit_functions[j](row) \u001B[38;5;241m/\u001B[39m fit_max\n\u001B[1;32m---> 89\u001B[0m     kde_max \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mones(embeddings\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32) \u001B[38;5;241m*\u001B[39m kde_fit_functions[j](x)\u001B[38;5;241m.\u001B[39mmax()\n\u001B[0;32m     90\u001B[0m     likelihoods\u001B[38;5;241m.\u001B[39mappend(tf\u001B[38;5;241m.\u001B[39mmap_fn(normalize_kde_fn, elems\u001B[38;5;241m=\u001B[39m(embeddings[:, j], kde_max)))\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mtranspose(tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(likelihoods))\n",
      "File \u001B[1;32mD:\\src\\maestria\\cern\\uncertainty_gan\\feature_densities\\feature_density_evaluator.py:89\u001B[0m, in \u001B[0;36mtf_calculate_normalized_likelihoods\u001B[1;34m(embeddings, kde_fit_functions, normalization_datapoints)\u001B[0m\n\u001B[0;32m     86\u001B[0m         row, fit_max \u001B[38;5;241m=\u001B[39m row_and_kde_max\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m kde_fit_functions[j](row) \u001B[38;5;241m/\u001B[39m fit_max\n\u001B[1;32m---> 89\u001B[0m     kde_max \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mones(embeddings\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32) \u001B[38;5;241m*\u001B[39m kde_fit_functions[j](x)\u001B[38;5;241m.\u001B[39mmax()\n\u001B[0;32m     90\u001B[0m     likelihoods\u001B[38;5;241m.\u001B[39mappend(tf\u001B[38;5;241m.\u001B[39mmap_fn(normalize_kde_fn, elems\u001B[38;5;241m=\u001B[39m(embeddings[:, j], kde_max)))\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mtranspose(tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(likelihoods))\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2023.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1187\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1184\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1187\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2023.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1202\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1199\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1201\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1202\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1206\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "hifkHx4m1sUm",
   "metadata": {
    "id": "hifkHx4m1sUm"
   },
   "source": [
    "# Save FD uncertainties normalized\n",
    "np.save(output_dir + f'{PARTICLE}_fd_uncertainty_normalized.npy', fd_uncertainty_normalized)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Uncertainty visualization",
   "id": "a7c57f700cc467dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba78fd7a8d05cd6c"
  },
  {
   "cell_type": "markdown",
   "id": "ae9bcbb42e00cc7d",
   "metadata": {
    "id": "ae9bcbb42e00cc7d"
   },
   "source": [
    "### Generation of FD embeddings"
   ]
  },
  {
   "cell_type": "code",
   "id": "eba581ce0d258384",
   "metadata": {
    "id": "eba581ce0d258384"
   },
   "source": [
    "# from feature_densities.feature_density_evaluator import create_embeddings_model\n",
    "# embeddings_model = create_embeddings_model(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "39d295a74f315c5",
   "metadata": {
    "id": "39d295a74f315c5"
   },
   "source": "# train_embeddings, train_predictions = embeddings_model.predict(dataset['feats_train'])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3314534dc025116",
   "metadata": {
    "id": "d3314534dc025116"
   },
   "source": "# test_embeddings, test_predictions = embeddings_model.predict(dataset['feats_val'])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd43e1e7d855bc0b",
   "metadata": {
    "id": "dd43e1e7d855bc0b"
   },
   "source": [
    "# !rm -r embeddings\n",
    "# !mkdir embeddings\n",
    "\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_train_embeddings.npy', train_embeddings)\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_train_predictions.npy', train_predictions)\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_test_embeddings.npy', test_embeddings)\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_test_predictions.npy', test_predictions)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
