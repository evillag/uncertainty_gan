{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/uncertainty_gan/blob/main/test_bench/TestBench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SmUSiLEY03cn",
        "outputId": "598fa307-a09f-4990-d50f-f65c0df87aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SmUSiLEY03cn",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/cern/data/results’: File exists\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:23.726620Z",
          "start_time": "2024-06-07T02:07:23.695479Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8953bf4723cb4b5",
        "outputId": "d255de5f-e951-498f-abb9-fcd48df26972"
      },
      "cell_type": "code",
      "source": [
        "IN_COLAB = True\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  # Using Google Drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  !git clone https://github.com/evillag/uncertainty_gan.git\n",
        "  !mv uncertainty_gan/mcd .\n",
        "  !mv uncertainty_gan/feature_densities .\n",
        "  !mv uncertainty_gan/test_bench .\n",
        "  %rm -rf uncertainty_gan/\n",
        "\n",
        "  !git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
        "  !mv lhcb-rich-gan-uncertainty/experiments .\n",
        "  !mv lhcb-rich-gan-uncertainty/src .\n",
        "  %rm -rf lhcb-rich-gan-uncertainty/\n",
        "  %rm -rf sample_data/\n",
        "  %pip install tensorflow-addons\n",
        "\n",
        "  # Dataset download and extraction\n",
        "  !unzip -qq drive/MyDrive/cern/data/rich.zip\n",
        "\n",
        "  # Model checkpoint download and extraction\n",
        "  !unzip -qq drive/MyDrive/cern/data/checkpoints_dropout_0.01.zip\n",
        "\n",
        "  # Model embeddings download and extraction\n",
        "  !unzip -qq drive/MyDrive/cern/data/embeddings.zip\n",
        "\n",
        "  # Results folder creation\n",
        "  !mkdir /content/drive/MyDrive/cern/data/results\n",
        "\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "print(f'IN_COLAB: {IN_COLAB}')"
      ],
      "id": "8953bf4723cb4b5",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'uncertainty_gan'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 131 (delta 64), reused 52 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (131/131), 17.34 MiB | 10.81 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "Cloning into 'lhcb-rich-gan-uncertainty'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Total 210 (delta 0), reused 0 (delta 0), pack-reused 210 (from 1)\u001b[K\n",
            "Receiving objects: 100% (210/210), 2.94 MiB | 8.75 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "IN_COLAB: True\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:06.215988Z",
          "start_time": "2024-06-07T02:07:03.029044Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from test_bench import get_checkpoint_name, load_particle_datasets, subsample_dataset\n",
        "from test_bench.model import MonteCarloDropoutModel\n"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "metadata": {
        "id": "b537f49152f44ec8"
      },
      "cell_type": "markdown",
      "source": [
        "# Test Bench for the Monte Carlo Dropout and Feature Density methods\n",
        "\n",
        "1. Select sample data\n",
        "2. Create a model\n",
        "3. Generate a single target with single inference mode\n",
        "4. Estimate MCD uncertainty\n",
        "5. Estimate FD uncertainty"
      ],
      "id": "b537f49152f44ec8"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:25.929299Z",
          "start_time": "2024-06-07T02:07:25.913657Z"
        },
        "id": "754279944432b7f1"
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "PARTICLE = 'pion'\n",
        "CHECKPOINT_DP = 0.01\n",
        "DROPOUT_TYPE = 'bernoulli_structured'\n",
        "CHECKPOINT_BASE = 'checkpoints/'\n",
        "DATA_DIR = 'rich/'\n",
        "SUB_SAMPLE_PERCENT = 0.02\n",
        "\n",
        "# MCD parameters\n",
        "MCD_ENSEMBLE_SIZE = 300\n",
        "\n",
        "# FD parameters\n",
        "embeddings_dir = f'embeddings/'\n",
        "\n",
        "# Save results path\n",
        "output_dir = 'results/'\n",
        "if IN_COLAB:\n",
        "  output_dir = f'/content/drive/MyDrive/cern/data/{output_dir}'"
      ],
      "id": "754279944432b7f1",
      "outputs": [],
      "execution_count": 12
    },
    {
      "metadata": {
        "id": "707cd509ae0c649a"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data and Sample selection"
      ],
      "id": "707cd509ae0c649a"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:45.171937Z",
          "start_time": "2024-06-07T02:07:27.682283Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73e7b604fa3d2457",
        "outputId": "15f39f8b-d0db-4e2f-9657-1a88b968fdc9"
      },
      "cell_type": "code",
      "source": [
        "dataset = load_particle_datasets(PARTICLE, DATA_DIR)"
      ],
      "id": "73e7b604fa3d2457",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and concatenating datasets:\n",
            "\trich/pion_-_down_2016_.csv\n",
            "\trich/pion_+_up_2016_.csv\n",
            "\trich/pion_-_up_2016_.csv\n",
            "\trich/pion2_+_down_2016_.csv\n",
            "\trich/pion2_-_up_2016_.csv\n",
            "\trich/pion_+_down_2016_.csv\n",
            "\trich/pion2_+_up_2016_.csv\n",
            "\trich/pion2_-_down_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 2000000\n",
            "scaler n_quantiles: 100000, time = 2.3753974437713623\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(948527, 3)\n",
            "targets_train shape\t(948527, 5)\n",
            "feats_val shape  \t(526449, 3)\n",
            "targets_val shape\t(526449, 5)\n",
            "\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:45.715412Z",
          "start_time": "2024-06-07T02:07:45.171937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31d95808b32bac06",
        "outputId": "bd7cc6f9-b724-46e1-8aae-cd720e888537"
      },
      "cell_type": "code",
      "source": [
        "# Draw a sample of the datasets\n",
        "x_sample, y_sample = subsample_dataset(dataset['feats_val'], dataset['targets_val'], SUB_SAMPLE_PERCENT)\n",
        "x_sample.shape, y_sample.shape"
      ],
      "id": "31d95808b32bac06",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([10528, 3]), TensorShape([10528, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "metadata": {
        "id": "605b58c1e3fc7f9"
      },
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "id": "605b58c1e3fc7f9"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:46.915006Z",
          "start_time": "2024-06-07T02:07:45.715412Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ff0b59fb3a914d",
        "outputId": "55f64de8-e940-4f58-f34c-3888e65d6bd1"
      },
      "cell_type": "code",
      "source": [
        "model = MonteCarloDropoutModel(\n",
        "    PARTICLE,\n",
        "    dropout_rate=CHECKPOINT_DP,\n",
        "    checkpoint_dir=CHECKPOINT_BASE + get_checkpoint_name(PARTICLE, CHECKPOINT_DP, DROPOUT_TYPE),\n",
        "    debug=True\n",
        ")\n",
        "generator = model.get_generator()"
      ],
      "id": "74ff0b59fb3a914d",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating model for pion with a dropout rate of 0.01\n",
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "\n",
            "Generator:\n",
            "\n",
            "Model: \"virtual_ensemble_model\"\n",
            "________________________________________________________________________________________________\n",
            " Layer (type)                              Output Shape                          Param #        \n",
            "================================================================================================\n",
            " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
            "                                                                                                \n",
            " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
            "                                                                                                \n",
            " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
            "                                                                                                \n",
            " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " DensePrediction (Dense)                   (None, 5)                             645            \n",
            "                                                                                                \n",
            "================================================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Discriminator:\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8)                    0         ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 256)                  100224    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100224 (391.50 KB)\n",
            "Trainable params: 100224 (391.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Checkpoint path: checkpoints/bernoulli_structured_dropout_line_test_cramer_drop_rate_0.01_pion\n",
            "\n",
            "0.001\n",
            "Last ckpt:  checkpoints/bernoulli_structured_dropout_line_test_cramer_drop_rate_0.01_pion/ckpt-21\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "metadata": {
        "id": "97d6eaa45996218e"
      },
      "cell_type": "markdown",
      "source": [
        "## Single model prediction"
      ],
      "id": "97d6eaa45996218e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:51.210066Z",
          "start_time": "2024-06-07T02:07:46.915179Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6fb303dc66f661b",
        "outputId": "cae6983c-396f-4dbd-de33-9684134a6abf"
      },
      "cell_type": "code",
      "source": [
        "generator.single_model_inference_mode()\n",
        "t_generated = generator.predict(x_sample)\n",
        "t_generated"
      ],
      "id": "c6fb303dc66f661b",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329/329 [==============================] - 5s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.34069768, -0.75628793,  0.6969006 , -0.26559168, -0.31229025],\n",
              "       [-1.0982914 , -1.8875299 , -0.8781852 , -1.5892601 , -1.7735574 ],\n",
              "       [ 0.5216234 ,  0.71218204,  0.3069851 , -0.73871994,  0.56137407],\n",
              "       ...,\n",
              "       [-0.8978682 , -1.5370419 , -0.8264393 , -1.3490703 , -1.496083  ],\n",
              "       [ 0.6642503 , -1.191757  ,  1.1401606 , -0.587104  , -0.62596244],\n",
              "       [ 0.05230185, -1.5115509 , -0.11086129, -0.85879713, -0.83539706]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# Save real and generated targets\n",
        "np.save(output_dir + f'{PARTICLE}_t_generated.npy', t_generated)\n",
        "np.save(output_dir + f'{PARTICLE}_y_real.npy', y_sample)"
      ],
      "metadata": {
        "id": "JpMqFDki0rkw"
      },
      "id": "JpMqFDki0rkw",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "121c68a8bd902eea"
      },
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo Dropout method"
      ],
      "id": "121c68a8bd902eea"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:56.116647Z",
          "start_time": "2024-06-07T02:07:51.210066Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c719499767f5934",
        "outputId": "d2139dbd-1829-427a-8ce2-f64bd8c33bb9"
      },
      "cell_type": "code",
      "source": [
        "from mcd.MCDEvaluator import evaluate_model as mcd_evaluate_model\n",
        "\n",
        "mcd_uncertainty, _ =  mcd_evaluate_model(model, x_sample, MCD_ENSEMBLE_SIZE)\n",
        "mcd_uncertainty\n"
      ],
      "id": "7c719499767f5934",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating ensemble(300) predictions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:11<00:00, 25.55it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10528, 5), dtype=float32, numpy=\n",
              "array([[0.4140107 , 0.44108438, 0.4775778 , 0.61591107, 0.79826605],\n",
              "       [0.3021742 , 0.45253897, 0.6264502 , 0.45789215, 0.52805537],\n",
              "       [0.13265656, 0.24616155, 0.09950522, 0.44376302, 0.8493591 ],\n",
              "       ...,\n",
              "       [0.34126005, 0.40928936, 0.57090616, 0.4934988 , 0.6186188 ],\n",
              "       [0.4377561 , 0.44249243, 0.41206178, 0.6765101 , 0.95058113],\n",
              "       [0.25326976, 0.43883586, 0.45758897, 0.52949965, 0.6475622 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-07T02:07:56.132262Z",
          "start_time": "2024-06-07T02:07:56.116647Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "363e0d79eb84e9fa",
        "outputId": "3bc9779e-d96e-436e-e4c0-801c4c05b00e"
      },
      "cell_type": "code",
      "source": [
        "mcd_uncertainty.shape"
      ],
      "id": "363e0d79eb84e9fa",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10528, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# Save MCD uncertainties\n",
        "np.save(output_dir + f'{PARTICLE}_mcd_uncertainty.npy', mcd_uncertainty)"
      ],
      "metadata": {
        "id": "Vs1mp9kZ1d4u"
      },
      "id": "Vs1mp9kZ1d4u",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7e2a5f809e9e7f1"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Densities method"
      ],
      "id": "d7e2a5f809e9e7f1"
    },
    {
      "metadata": {
        "id": "83a242ecd57dbec9"
      },
      "cell_type": "markdown",
      "source": [
        "### Uncertainty estimation"
      ],
      "id": "83a242ecd57dbec9"
    },
    {
      "metadata": {
        "id": "622705127bfa96df"
      },
      "cell_type": "markdown",
      "source": [],
      "id": "622705127bfa96df"
    },
    {
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "ExecuteTime": {
          "start_time": "2024-06-07T02:09:08.234787Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5e680e33c07c6bd",
        "outputId": "614d739a-0e97-48c1-a6ec-12e95e1098af"
      },
      "cell_type": "code",
      "source": [
        "from feature_densities.feature_density_evaluator import evaluate_model as fd_evaluate_model\n",
        "\n",
        "train_embeddings = np.load(embeddings_dir + f'{PARTICLE}_train_embeddings.npy')\n",
        "print(train_embeddings.shape)\n",
        "\n",
        "fd_uncertainty_integration, _ = fd_evaluate_model(model, x_sample, known_embeddings=train_embeddings, likelihood_method='integration')\n",
        "\n",
        "print('Feature Densities using INTEGRATION uncertainty score for x_sample:')\n",
        "fd_uncertainty_integration"
      ],
      "id": "f5e680e33c07c6bd",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(948325, 128)\n",
            "Generating an embeddings model\n",
            "Fitting KDE functions to known embeddings\n",
            "Calculating sample´s embeddings\n",
            "329/329 [==============================] - 2s 3ms/step\n",
            "Estimating sample´s feature densities\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/10528 [00:26<37:32:37, 12.84s/it]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save FD uncertainties with integration\n",
        "np.save(output_dir + f'{PARTICLE}_fd_uncertainty_integration.npy', fd_uncertainty_integration)"
      ],
      "metadata": {
        "id": "zONmkpvs1rMd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zONmkpvs1rMd"
    },
    {
      "metadata": {
        "id": "8708230d258d1631"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "fd_uncertainty_normalized, _ = fd_evaluate_model(model, x_sample, known_embeddings=train_embeddings, likelihood_method='normalized')\n",
        "\n",
        "print('Feature Densities using NORMALIZED uncertainty score for x_sample:')\n",
        "fd_uncertainty_normalized"
      ],
      "id": "8708230d258d1631"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save FD uncertainties normalized\n",
        "np.save(output_dir + f'{PARTICLE}_fd_uncertainty_normalized.npy', fd_uncertainty_normalized)"
      ],
      "metadata": {
        "id": "hifkHx4m1sUm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hifkHx4m1sUm"
    },
    {
      "metadata": {
        "id": "ae9bcbb42e00cc7d"
      },
      "cell_type": "markdown",
      "source": [
        "### Generation of FD embeddings"
      ],
      "id": "ae9bcbb42e00cc7d"
    },
    {
      "metadata": {
        "id": "eba581ce0d258384"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# from feature_densities.feature_density_evaluator import create_embeddings_model\n",
        "# embeddings_model = create_embeddings_model(model)"
      ],
      "id": "eba581ce0d258384"
    },
    {
      "metadata": {
        "id": "39d295a74f315c5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# train_embeddings, train_predictions = embeddings_model.predict(dataset['feats_train'])"
      ],
      "id": "39d295a74f315c5"
    },
    {
      "metadata": {
        "id": "d3314534dc025116"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# test_embeddings, test_predictions = embeddings_model.predict(dataset['feats_val'])"
      ],
      "id": "d3314534dc025116"
    },
    {
      "metadata": {
        "id": "dd43e1e7d855bc0b"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# !rm -r embeddings\n",
        "# !mkdir embeddings\n",
        "\n",
        "# np.save(embeddings_dir + f'{PARTICLE}_train_embeddings.npy', train_embeddings)\n",
        "# np.save(embeddings_dir + f'{PARTICLE}_train_predictions.npy', train_predictions)\n",
        "# np.save(embeddings_dir + f'{PARTICLE}_test_embeddings.npy', test_embeddings)\n",
        "# np.save(embeddings_dir + f'{PARTICLE}_test_predictions.npy', test_predictions)"
      ],
      "id": "dd43e1e7d855bc0b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}