{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:06.215988Z",
     "start_time": "2024-06-07T02:07:03.029044Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "from test_bench import get_checkpoint_name, load_particle_datasets, subsample_dataset\n",
    "from test_bench.model import MonteCarloDropoutModel\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:23.726620Z",
     "start_time": "2024-06-07T02:07:23.695479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IN_COLAB = True\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  # Using Google Drive\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  # your path to the data\n",
    "  !ls '/content/drive/MyDrive/data/rich'\n",
    "  \n",
    "  !git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
    "  !mv lhcb-rich-gan-uncertainty/experiments .\n",
    "  !mv lhcb-rich-gan-uncertainty/src .\n",
    "  !rm -r lhcb-rich-gan-uncertainty/\n",
    "  !rm -r sample_data/\n",
    "  !pip install tensorflow-addons\n",
    "  \n",
    "  # Dataset download and extraction\n",
    "  !unzip -qq drive/MyDrive/cern/data/rich.zip\n",
    "  \n",
    "  # Model checkpoint download and extraction\n",
    "  !unzip -qq drive/MyDrive/cern/data/checkpoints_dropout_0.01.zip  \n",
    "  \n",
    "except:\n",
    "  IN_COLAB = False  \n",
    "  \n",
    "print(f'IN_COLAB: {IN_COLAB}')"
   ],
   "id": "8953bf4723cb4b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_COLAB: False\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test Bench for the Monte Carlo Dropout and Feature Density methods\n",
    "\n",
    "1. Select sample data\n",
    "2. Create a model\n",
    "3. Generate a single target with single inference mode\n",
    "4. Estimate MCD uncertainty\n",
    "5. Estimate FD uncertainty"
   ],
   "id": "b537f49152f44ec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:25.929299Z",
     "start_time": "2024-06-07T02:07:25.913657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "PARTICLE = 'pion'\n",
    "CHECKPOINT_DP = 0.01\n",
    "DROPOUT_TYPE = 'bernoulli_structured'\n",
    "CHECKPOINT_BASE = 'checkpoints/'\n",
    "DATA_DIR = 'rich/'\n",
    "SUB_SAMPLE_PERCENT = 0.1\n",
    "\n",
    "# MCD parameters\n",
    "MCD_ENSEMBLE_SIZE = 300\n",
    "\n",
    "#FD parameters\n",
    "embeddings_dir = f'embeddings/'\n",
    "if IN_COLAB:\n",
    "    embeddings_dir = 'drive/MyDrive/Colab Notebooks/' + embeddings_dir\n"
   ],
   "id": "754279944432b7f1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data and Sample selection",
   "id": "707cd509ae0c649a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:45.171937Z",
     "start_time": "2024-06-07T02:07:27.682283Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_particle_datasets(PARTICLE, DATA_DIR)",
   "id": "73e7b604fa3d2457",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and concatenating datasets:\n",
      "\trich\\pion2_+_down_2016_.csv\n",
      "\trich\\pion2_+_up_2016_.csv\n",
      "\trich\\pion2_-_down_2016_.csv\n",
      "\trich\\pion2_-_up_2016_.csv\n",
      "\trich\\pion_+_down_2016_.csv\n",
      "\trich\\pion_+_up_2016_.csv\n",
      "\trich\\pion_-_down_2016_.csv\n",
      "\trich\\pion_-_up_2016_.csv\n",
      "splitting to train/val/test\n",
      "fitting the scaler\n",
      "scaler train sample size: 2000000\n",
      "scaler n_quantiles: 100000, time = 1.3087596893310547\n",
      "scaling train set\n",
      "scaling test set\n",
      "converting dtype to <class 'numpy.float32'>\n",
      "feats_train shape\t(948325, 3)\n",
      "targets_train shape\t(948325, 5)\n",
      "feats_val shape  \t(527302, 3)\n",
      "targets_val shape\t(527302, 5)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:45.715412Z",
     "start_time": "2024-06-07T02:07:45.171937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Draw a sample of the datasets\n",
    "x_sample, y_sample = subsample_dataset(dataset['feats_val'], dataset['targets_val'], SUB_SAMPLE_PERCENT)\n",
    "x_sample.shape, y_sample.shape"
   ],
   "id": "31d95808b32bac06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([52730, 3]), TensorShape([52730, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model creation",
   "id": "605b58c1e3fc7f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:46.915006Z",
     "start_time": "2024-06-07T02:07:45.715412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MonteCarloDropoutModel(\n",
    "    PARTICLE,\n",
    "    dropout_rate=CHECKPOINT_DP,\n",
    "    checkpoint_dir=CHECKPOINT_BASE + get_checkpoint_name(PARTICLE, CHECKPOINT_DP, DROPOUT_TYPE),\n",
    "    debug=True\n",
    ")\n",
    "generator = model.get_generator()"
   ],
   "id": "74ff0b59fb3a914d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating model for pion with a dropout rate of 0.01\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "\n",
      "Generator:\n",
      "\n",
      "Model: \"virtual_ensemble_model\"\n",
      "________________________________________________________________________________________________\n",
      " Layer (type)                              Output Shape                          Param #        \n",
      "================================================================================================\n",
      " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
      "                                                                                                \n",
      " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
      "                                                                                                \n",
      " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
      "                                                                                                \n",
      " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
      "                                                                                                \n",
      " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
      "                                                                                                \n",
      " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
      "                                                                                                \n",
      " DensePrediction (Dense)                   (None, 5)                             645            \n",
      "                                                                                                \n",
      "================================================================================================\n",
      "Total params: 75,397\n",
      "Trainable params: 75,397\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Discriminator:\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8)            0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 256)          100224      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100,224\n",
      "Trainable params: 100,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "Checkpoint path: checkpoints/bernoulli_structured_dropout_line_test_cramer_drop_rate_0.01_pion\n",
      "\n",
      "0.001\n",
      "Last ckpt:  checkpoints/bernoulli_structured_dropout_line_test_cramer_drop_rate_0.01_pion\\ckpt-21\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single model prediction",
   "id": "97d6eaa45996218e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:51.210066Z",
     "start_time": "2024-06-07T02:07:46.915179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator.single_model_inference_mode()\n",
    "t_generated = generator.predict(x_sample)\n",
    "t_generated"
   ],
   "id": "c6fb303dc66f661b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1648/1648 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.2360675 , -1.1847739 , -1.5161496 , -1.1183429 , -1.2257295 ],\n",
       "       [-0.04207586, -1.2648206 , -0.12901922, -0.61363685, -0.67083454],\n",
       "       [-0.9352725 , -2.4061308 , -0.4834558 , -2.185705  , -2.367094  ],\n",
       "       ...,\n",
       "       [-0.21783379, -1.2257509 , -0.4460397 , -0.93520015, -1.0148213 ],\n",
       "       [ 1.431718  , -0.8172986 ,  1.2122009 , -1.0378337 , -0.83755225],\n",
       "       [-2.1402342 , -0.8638425 , -2.4000866 , -0.78204876, -0.84564716]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Monte Carlo Dropout method",
   "id": "121c68a8bd902eea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:56.116647Z",
     "start_time": "2024-06-07T02:07:51.210066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mcd.MCDEvaluator import evaluate_model\n",
    "\n",
    "mcd_uncertainty, _ =  evaluate_model(model, x_sample, MCD_ENSEMBLE_SIZE)\n",
    "mcd_uncertainty\n"
   ],
   "id": "7c719499767f5934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ensemble(300) predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 61.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(52730, 5), dtype=float32, numpy=\n",
       "array([[0.40873483, 0.3998819 , 0.61187154, 0.4298904 , 0.48295096],\n",
       "       [0.37222233, 0.47420976, 0.51377887, 0.57635206, 0.69689095],\n",
       "       [0.48894337, 0.44581538, 0.5583058 , 0.55381644, 0.7149202 ],\n",
       "       ...,\n",
       "       [0.33421418, 0.5330626 , 0.57754517, 0.5674262 , 0.6533295 ],\n",
       "       [0.19450414, 0.3283254 , 0.14817482, 0.4794714 , 0.8294769 ],\n",
       "       [0.1972451 , 0.278714  , 0.27302375, 0.2856447 , 0.29262617]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:07:56.132262Z",
     "start_time": "2024-06-07T02:07:56.116647Z"
    }
   },
   "cell_type": "code",
   "source": "mcd_uncertainty.shape",
   "id": "363e0d79eb84e9fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([52730, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Densities method",
   "id": "d7e2a5f809e9e7f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Uncertainty estimation",
   "id": "83a242ecd57dbec9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "622705127bfa96df"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-07T02:09:08.234787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from feature_densities.feature_density_evaluator import evaluate_model as fd_evaluate_model\n",
    "\n",
    "train_embeddings = np.load(embeddings_dir + f'{PARTICLE}_train_embeddings.npy')\n",
    "print(train_embeddings.shape)\n",
    "\n",
    "fd_uncertainty, _ = fd_evaluate_model(model, x_sample, known_embeddings=train_embeddings, likelihood_method='integration')\n",
    "\n",
    "print('Feature Densities using INTEGRATION uncertainty score for x_sample:')\n",
    "fd_uncertainty"
   ],
   "id": "f5e680e33c07c6bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948325, 128)\n",
      "Generating an embeddings model\n",
      "Fitting KDE functions to known embeddings\n",
      "Calculating sample´s embeddings\n",
      "1648/1648 [==============================] - 4s 2ms/step\n",
      "Estimating sample´s feature densities\n",
      "Calculating likelihoods with integration method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fd_uncertainty, _ = fd_evaluate_model(model, x_sample, known_embeddings=train_embeddings, likelihood_method='normalized')\n",
    "\n",
    "print('Feature Densities using NORMALIZED uncertainty score for x_sample:')\n",
    "fd_uncertainty"
   ],
   "id": "8708230d258d1631"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generation of FD embeddings",
   "id": "ae9bcbb42e00cc7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from feature_densities.feature_density_evaluator import create_embeddings_model\n",
    "# embeddings_model = create_embeddings_model(model)"
   ],
   "id": "eba581ce0d258384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# train_embeddings, train_predictions = embeddings_model.predict(dataset['feats_train'])",
   "id": "39d295a74f315c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# test_embeddings, test_predictions = embeddings_model.predict(dataset['feats_val'])",
   "id": "d3314534dc025116"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !rm -r embeddings\n",
    "# !mkdir embeddings\n",
    "\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_train_embeddings.npy', train_embeddings)\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_train_predictions.npy', train_predictions)\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_test_embeddings.npy', test_embeddings)\n",
    "# np.save(embeddings_dir + f'{PARTICLE}_test_predictions.npy', test_predictions)"
   ],
   "id": "dd43e1e7d855bc0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
