{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evillag/uncertainty_gan/blob/main/%5BFeature_Densities%5D_CERN_uncertainties.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PgWNyAwfzx"
      },
      "source": [
        "# Setup\n",
        "\n",
        "1.   Download Rich detector dataset (from GDrive)\n",
        "2.   Download [Uncertainty code](https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git) from [paper]().\n",
        "3.   Install dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxlGS2tW8Cat",
        "outputId": "0963dd37-4058-4b1e-e070-b89d9915b4de",
        "ExecuteTime": {
          "end_time": "2024-03-06T04:20:31.281158Z",
          "start_time": "2024-03-06T04:20:31.235162Z"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSVQMOYHBop9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e7fcff-ea86-40d4-943a-0295dd61cd67",
        "ExecuteTime": {
          "end_time": "2024-03-06T04:20:31.297162Z",
          "start_time": "2024-03-06T04:20:31.284159Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "kaon2_+_down_2016_.csv\tkaon_+_up_2016_.csv    pion2_+_down_2016_.csv  pion_+_up_2016_.csv\n",
            "kaon2_-_down_2016_.csv\tkaon_-_up_2016_.csv    pion2_-_down_2016_.csv  pion_-_up_2016_.csv\n",
            "kaon2_+_up_2016_.csv\tmuon_+_down_2016_.csv  pion2_+_up_2016_.csv    proton_+_down_2016_.csv\n",
            "kaon2_-_up_2016_.csv\tmuon_-_down_2016_.csv  pion2_-_up_2016_.csv    proton_-_down_2016_.csv\n",
            "kaon_+_down_2016_.csv\tmuon_+_up_2016_.csv    pion_+_down_2016_.csv   proton_+_up_2016_.csv\n",
            "kaon_-_down_2016_.csv\tmuon_-_up_2016_.csv    pion_-_down_2016_.csv   proton_-_up_2016_.csv\n",
            "Cloning into 'lhcb-rich-gan-uncertainty'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Total 210 (delta 0), reused 0 (delta 0), pack-reused 210\u001b[K\n",
            "Receiving objects: 100% (210/210), 2.94 MiB | 26.89 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "IN_COLAB = True\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !ls '/content/drive/MyDrive/data/rich'\n",
        "  !git clone https://gitlab.com/lambda-hse/lhcb-rich-gan-uncertainty.git\n",
        "  !mv lhcb-rich-gan-uncertainty/experiments .\n",
        "  !mv lhcb-rich-gan-uncertainty/src .\n",
        "  !rm -r lhcb-rich-gan-uncertainty/\n",
        "  !rm -r sample_data/\n",
        "  !pip install tensorflow-addons\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hwJdDhUTBoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c71650-b65c-453c-d67b-6f344db955cf",
        "ExecuteTime": {
          "end_time": "2024-03-06T04:20:31.313667Z",
          "start_time": "2024-03-06T04:20:31.298161Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from experiments.efficiency.uncertainty_model_train import train_model\n",
        "from experiments.efficiency.uncertainty_models import uncertainty_mlp\n",
        "from experiments.efficiency.uncertainty_utils import (\n",
        "    efficiency_bands_with_uncertainty, efficiency_momentum_with_uncertainty)\n",
        "from experiments.efficiency.utils import (\n",
        "    efficiency_bands, efficiency_momentum, ensemble_and_ref_model_inference,\n",
        "    ensemble_and_ref_model_inference_on_bands, tf_to_numpy_dataset,\n",
        "    threshold_selection)\n",
        "\n",
        "from src.cramer_gan_trainer import CramerGANTrainer\n",
        "from src.dataset import CramerGANDataset\n",
        "from src.datasets.utils_rich import (get_merged_typed_dataset,\n",
        "                                     parse_dataset_np, parse_example)\n",
        "from src.models.gans.discriminators.fcn_disc import RICHDiscriminator\n",
        "from src.models.gans.generators.fcn_gen import RichMCDropFunc, VirtualEnsembleModel\n",
        "\n",
        "from scipy.spatial import distance\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f'GPU available? {tf.config.list_physical_devices(\"GPU\")}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8KR6Qnm0tz_",
        "ExecuteTime": {
          "end_time": "2024-03-06T04:20:31.329676Z",
          "start_time": "2024-03-06T04:20:31.314676Z"
        }
      },
      "outputs": [],
      "source": [
        "# GLOBALS\n",
        "PARTICLES = [\"pion\", 'kaon', \"muon\", \"proton\"]\n",
        "# DROPOUTS = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "DROPOUTS = [0.25, 0.3, 0.35, 0.4]\n",
        "ENSEMBLES = [16, 32, 64, 128, 256]\n",
        "NUM_REPS = 10\n",
        "SUB_SAMPLE_SIZE = .3\n",
        "THRESHOLD = 1.0\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/data/rich' if IN_COLAB else '../data/rich'\n",
        "CHECKPOINT_BASE = '/content/drive/MyDrive/Documentos/Maestria ITCR/cern/checkpoints/' if IN_COLAB else '../checkpoints'\n",
        "CKPT_NUMBER = 'ckpt-21'\n",
        "\n",
        "def get_checkpoint_name(particle):\n",
        "  return f'bernoulli_structured_dropout_line_test_cramer_weighted_{particle}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpnkp-nlxkG3"
      },
      "source": [
        "# Particle selection and dataset split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGf2lW-IUGuV"
      },
      "source": [
        " Line experiment is mainly focused on testing whether the ensemble-based uncertainty is applicable for out-of-distribution data. To check this, we make train/test split as two disjoint sets. Taking the symmetry of the data after standardization, we split the data by the line $y=x$ (we consider pseudorapidity (ETA) and momentum (P) for split).\n",
        "\n",
        " ------\n",
        " Notes\n",
        "\n",
        "\n",
        "*   Data is split based on two dimensions arbitrarily (P abd ETA)\n",
        "*   Data is scaled to follow a normal distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOupXOpGadTx"
      },
      "source": [
        "- Features\n",
        "  - Brunel_P\n",
        "  - Brunel_ETA\n",
        "  - nTracks_Brunel\n",
        "\n",
        "- Targets:\n",
        "    - RichDLLe\n",
        "    - RichDLLk\n",
        "    - RichDLLmu\n",
        "    - RichDLLp\n",
        "    - RichDLLbt\n",
        "\n",
        "- Discarded\n",
        "  - probe_sWeight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQAdZvDFTzUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fbd3af-92ed-4ed6-f37d-8e0893092b86",
        "ExecuteTime": {
          "end_time": "2024-03-06T04:21:24.367243Z",
          "start_time": "2024-03-06T04:20:31.331674Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and concatenating datasets:\n",
            "\t/content/drive/MyDrive/data/rich/pion_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion_-_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion2_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion2_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion2_+_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion2_-_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/pion_+_up_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 2000000\n",
            "scaler n_quantiles: 100000, time = 1.9535324573516846\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(947640, 3)\n",
            "targets_train shape\t(947640, 5)\n",
            "feats_val shape  \t(524888, 3)\n",
            "targets_val shape\t(524888, 5)\n",
            "\n",
            "Reading and concatenating datasets:\n",
            "\t/content/drive/MyDrive/data/rich/kaon_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon_-_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon_+_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon2_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon2_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon2_-_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon2_+_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/kaon_-_down_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 2000000\n",
            "scaler n_quantiles: 100000, time = 1.9311003684997559\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(934803, 3)\n",
            "targets_train shape\t(934803, 5)\n",
            "feats_val shape  \t(531999, 3)\n",
            "targets_val shape\t(531999, 5)\n",
            "\n",
            "Reading and concatenating datasets:\n",
            "\t/content/drive/MyDrive/data/rich/muon_+_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/muon_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/muon_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/muon_-_up_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 1000000\n",
            "scaler n_quantiles: 100000, time = 1.2058756351470947\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(515683, 3)\n",
            "targets_train shape\t(515683, 5)\n",
            "feats_val shape  \t(240837, 3)\n",
            "targets_val shape\t(240837, 5)\n",
            "\n",
            "Reading and concatenating datasets:\n",
            "\t/content/drive/MyDrive/data/rich/proton_+_up_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/proton_+_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/proton_-_down_2016_.csv\n",
            "\t/content/drive/MyDrive/data/rich/proton_-_up_2016_.csv\n",
            "splitting to train/val/test\n",
            "fitting the scaler\n",
            "scaler train sample size: 1000000\n",
            "scaler n_quantiles: 100000, time = 1.135042667388916\n",
            "scaling train set\n",
            "scaling test set\n",
            "converting dtype to <class 'numpy.float32'>\n",
            "feats_train shape\t(454523, 3)\n",
            "targets_train shape\t(454523, 5)\n",
            "feats_val shape  \t(272358, 3)\n",
            "targets_val shape\t(272358, 5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def _split_by_line(df, slope=1, intercept=0):\n",
        "  top_half = df[df['Brunel_ETA'] > df['Brunel_P'] * slope + intercept]\n",
        "  bottom_half = df[df['Brunel_ETA'] <= df['Brunel_P'] * slope + intercept]\n",
        "\n",
        "  top_half = top_half.reset_index(drop=True)\n",
        "  bottom_half = bottom_half.reset_index(drop=True)\n",
        "\n",
        "  return top_half, bottom_half\n",
        "\n",
        "def split_by_line(df_train, df_test):\n",
        "  return _split_by_line(df_train)[0], _split_by_line(df_test)[1]\n",
        "\n",
        "def load_particle_datasets(particle, data_dir=DATA_DIR):\n",
        "  \"\"\" The returned dictionary has this format:\n",
        "      {\n",
        "        \"<particle_name>\": {\n",
        "          'data_train': data_train,\n",
        "          'data_val': data_val,\n",
        "          'scaler': scaler,\n",
        "          'feats_train': feats_train,\n",
        "          'targets_train': targets_train,\n",
        "          'feats_val': feats_val,\n",
        "          'targets_val': targets_val\n",
        "        }\n",
        "      }\n",
        "  \"\"\"\n",
        "  data_train, data_val, scaler = get_merged_typed_dataset(data_dir, particle, dtype=np.float32, log=True,\n",
        "                                                          sample_fn=split_by_line)\n",
        "  feats_train, targets_train, _ = parse_dataset_np(data_train)\n",
        "  feats_val, targets_val, _ = parse_dataset_np(data_val)\n",
        "\n",
        "  print(f'feats_train shape\\t{feats_train.shape}\\n'\n",
        "        f'targets_train shape\\t{targets_train.shape}\\n'\n",
        "        f'feats_val shape  \\t{feats_val.shape}\\n'\n",
        "        f'targets_val shape\\t{targets_val.shape}\\n')\n",
        "\n",
        "  return {\n",
        "      'data_train': data_train,\n",
        "      'data_val': data_val,\n",
        "      'scaler': scaler,\n",
        "      'feats_train': feats_train,\n",
        "      'targets_train': targets_train,\n",
        "      'feats_val': feats_val,\n",
        "      'targets_val': targets_val\n",
        "  }\n",
        "\n",
        "datasets = {particle: load_particle_datasets(particle) for particle in PARTICLES}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpZB6sYFa93G"
      },
      "source": [
        "# Models creation (restoring from checkpoint)\n",
        "\n",
        " This chapter contains the only model definition and restores the model from the checkpoint. It does not contain training/evaluation routines since it was done in another notebook (look LineTestTrain.ipynb notebook)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCJfnnQ1Np8o"
      },
      "source": [
        "We use Cramer GAN modification to train generator learn the distribution. [Link](https://arxiv.org/abs/1705.10743) to Cramer GAN for more details. The training configuration:\n",
        "\n",
        "* Batch size: 1000\n",
        "* Critic steps: 15\n",
        "* Generator optimizer: RMSProp with learning rate 0.0002\n",
        "* iscriminator optimizer: RMSProp with learning rate 0.0002\n",
        "* Use weights: True\n",
        "* Number of epochs: 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_Jd4tHwa4zu",
        "ExecuteTime": {
          "end_time": "2024-03-06T04:21:24.647201Z",
          "start_time": "2024-03-06T04:21:24.368243Z"
        }
      },
      "outputs": [],
      "source": [
        "class MonteCarloDroupoutModel:\n",
        "  def __init__(self, particle, dropout_rate,\n",
        "               log_dir='log_dir_tmp',\n",
        "               checkpoint_base=CHECKPOINT_BASE,\n",
        "               chekpoint_file=CKPT_NUMBER,\n",
        "               debug=False):\n",
        "\n",
        "    self.particle = particle\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.log_dir = log_dir\n",
        "\n",
        "    print(f'Generating model for {particle} with a dropout rate of {dropout_rate}')\n",
        "\n",
        "    self._gen_config = {\n",
        "        'drop_rate': dropout_rate,\n",
        "        # 'dropout_type': 'bernoulli_structured',\n",
        "        'dropout_type': 'bernoulli',\n",
        "        # 'drop_kwargs': {'patch_size': 3}\n",
        "    }\n",
        "\n",
        "    self._generator = RichMCDropFunc(**self._gen_config)\n",
        "    self._generator.build((None, 3))\n",
        "    self._discriminator = RICHDiscriminator()\n",
        "\n",
        "    self._checkpoint_dir = os.path.join(checkpoint_base, get_checkpoint_name(self.particle))\n",
        "    self._filename = os.path.join(self._checkpoint_dir, chekpoint_file)\n",
        "\n",
        "    if debug:\n",
        "      print(\"\\nGenerator:\\n\")\n",
        "      print(self._generator.summary(line_length=96))\n",
        "      print(\"\\nDiscriminator:\\n\")\n",
        "      print(self._discriminator.summary())\n",
        "      print(f\"\\nCheckpoint filename: {self._filename}\\n\")\n",
        "\n",
        "\n",
        "    # Model was trained with tensorflow 2.10.1, use the legacy optimizer\n",
        "    self._generator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
        "    self._discriminator_optimizer = tf.keras.optimizers.legacy.RMSprop(2e-4)\n",
        "\n",
        "    self._trainer_config = {\n",
        "      'generator': self._generator,\n",
        "      'discriminator': self._discriminator,\n",
        "      'generator_optimizer': self._generator_optimizer,\n",
        "      'discriminator_optimizer': self._discriminator_optimizer,\n",
        "      'checkpoint_dir': self._checkpoint_dir,\n",
        "      'log_dir': log_dir\n",
        "    }\n",
        "    trainer = CramerGANTrainer(**self._trainer_config)\n",
        "    # Restore pretrained model\n",
        "    trainer.restore(self._filename)\n",
        "\n",
        "  def __str__(self):\n",
        "     return f\"{self.particle}_{self.dropout_rate}\"\n",
        "\n",
        "  def get_generator(self) -> VirtualEnsembleModel:\n",
        "    return self._generator\n",
        "\n",
        "\n",
        "# Test model creation\n",
        "#mc_model = MonteCarloDroupoutModel('kaon', 0.1, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating model for kaon with a dropout rate of 0.1\n",
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "\n",
            "Generator:\n",
            "\n",
            "Model: \"virtual_ensemble_model\"\n",
            "________________________________________________________________________________________________\n",
            " Layer (type)                              Output Shape                          Param #        \n",
            "================================================================================================\n",
            " Inputs (InputLayer)                       [(None, 3)]                           0              \n",
            "                                                                                                \n",
            " NoiseInjection (NoiseInjection)           (None, 67)                            0              \n",
            "                                                                                                \n",
            " Layer_0/Dense (Dense)                     (None, 128)                           8704           \n",
            "                                                                                                \n",
            " Layer_0/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_0/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_1/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_1/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_2/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_2/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_3/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_3/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/Dense (Dense)                     (None, 128)                           16512          \n",
            "                                                                                                \n",
            " Layer_4/LeakyReLU (LeakyReLU)             (None, 128)                           0              \n",
            "                                                                                                \n",
            " Layer_4/DropoutTrain (DropoutTrain)       (None, 128)                           0              \n",
            "                                                                                                \n",
            " DensePrediction (Dense)                   (None, 5)                             645            \n",
            "                                                                                                \n",
            "================================================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Discriminator:\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8)                    0         ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 256)                  100224    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100224 (391.50 KB)\n",
            "Trainable params: 100224 (391.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Checkpoint filename: /content/drive/MyDrive/Documentos/Maestria ITCR/cern/checkpoints/bernoulli_structured_dropout_line_test_cramer_weighted_kaon/ckpt-21\n",
            "\n",
            "0.001\n",
            "Model: \"virtual_ensemble_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Inputs (InputLayer)         [(None, 3)]               0         \n",
            "                                                                 \n",
            " NoiseInjection (NoiseInjec  (None, 67)                0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " Layer_0/Dense (Dense)       (None, 128)               8704      \n",
            "                                                                 \n",
            " Layer_0/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_0/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_1/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_1/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_1/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_2/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_2/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_2/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_3/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_3/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_3/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_4/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_4/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_4/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " DensePrediction (Dense)     (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75397 (294.52 KB)\n",
            "Trainable params: 75397 (294.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mc_model = MonteCarloDroupoutModel('kaon', 0.1, debug=True)\n",
        "gen1 = mc_model.get_generator()\n",
        "gen1.single_model_inference_mode()\n",
        "gen1.summary()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-06T04:34:16.727301Z",
          "start_time": "2024-03-06T04:34:16.386275Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7imwp5dae4GT",
        "outputId": "c925a634-b4f2-4d8f-934d-a14d9322e3ee"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96711825, 0.44602729, 0.5387772 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "input_data = np.random.rand(1, 3)\n",
        "input_data"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-06T04:34:34.304795Z",
          "start_time": "2024-03-06T04:34:34.299795Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZWVQaXue4GV",
        "outputId": "faf7d92c-8a27-4e45-d357-fa565987c171"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0440134 ,  0.7154342 , -0.6578866 , -0.76405543,  0.09815606]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "gen1.predict(input_data)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-06T04:34:41.243840Z",
          "start_time": "2024-03-06T04:34:41.063332Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1LVfEcge4GX",
        "outputId": "ae79ab88-5183-4bc3-dc53-82f8f2794e77"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(gen1.layers)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-06T04:54:39.836051Z",
          "start_time": "2024-03-06T04:54:39.825052Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGzUYw4le4GY",
        "outputId": "75e219a3-4422-4f13-a4e8-f1c53c02f10e"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "\n",
        "XX = gen1.input\n",
        "# YY = gen1.layers[14].output\n",
        "YY =  tf.keras.layers.Dense(128)(gen1.get_layer(\"Layer_1\n",
        "/Dense\").output)\n",
        "new_model = Model(XX, YY)\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW1kqb7VohaA",
        "outputId": "c33e55d3-01fc-4f97-e5fb-c19c1f64c558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Inputs (InputLayer)         [(None, 3)]               0         \n",
            "                                                                 \n",
            " NoiseInjection (NoiseInjec  (None, 67)                0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " Layer_0/Dense (Dense)       (None, 128)               8704      \n",
            "                                                                 \n",
            " Layer_0/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_0/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_1/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_1/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_1/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_2/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_2/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_2/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_3/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Layer_3/LeakyReLU (LeakyRe  (None, 128)               0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " Layer_3/DropoutTrain (Drop  (None, 128)               0         \n",
            " outTrain)                                                       \n",
            "                                                                 \n",
            " Layer_4/Dense (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91264 (356.50 KB)\n",
            "Trainable params: 91264 (356.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "<tf.Tensor 'virtual_ensemble_model/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'virtual_ensemble_model/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> was defined here:\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    File \"<ipython-input-9-6259e9b12e85>\", line 1, in <cell line: 1>\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 888, in _call\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 695, in _initialize\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 178, in trace_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 283, in _maybe_define_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 310, in _create_concrete_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\", line 1059, in func_graph_from_py_func\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 598, in wrapped_fn\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\", line 41, in autograph_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1681, in run\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 3271, in call_for_each_replica\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 4069, in _call_for_each_replica\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n    File \"/content/src/models/gans/generators/fcn_gen.py\", line 68, in call\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1217, in if_stmt\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1270, in _py_if_stmt\n    File \"/content/src/models/gans/generators/fcn_gen.py\", line 79, in call\n    File \"/content/src/models/gans/generators/fcn_gen.py\", line 10, in bernoulli_dropout\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5979, in dropout\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py\", line 5514, in dropout_v2\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py\", line 5809, in _dropout\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\", line 4898, in where_v2\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 10083, in select_v2\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\", line 796, in _apply_op_helper\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\", line 670, in _create_op_internal\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 2652, in _create_op_internal\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 1160, in from_node_def\n\nThe tensor <tf.Tensor 'virtual_ensemble_model/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=predict_function, id=133006349326304), which is out of scope.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6db314ddf7e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(Xresult.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Xresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <tf.Tensor 'virtual_ensemble_model/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'virtual_ensemble_model/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> was defined here:\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    File \"<ipython-input-9-6259e9b12e85>\", line 1, in <cell line: 1>\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 888, in _call\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 695, in _initialize\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 178, in trace_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 283, in _maybe_define_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 310, in _create_concrete_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\", line 1059, in func_graph_from_py_func\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 598, in wrapped_fn\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\", line 41, in autograph_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1681, in run\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 3271, in call_for_each_replica\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 4069, in _call_for_each_replica\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n    File \"/content/src/models/gans/generators/fcn_gen.py\", line 68, in call\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1217, in if_stmt\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1270, in _py_if_stmt\n    File \"/content/src/models/gans/generators/fcn_gen.py\", line 79, in call\n    File \"/content/src/models/gans/generators/fcn_gen.py\", line 10, in bernoulli_dropout\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5979, in dropout\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py\", line 5514, in dropout_v2\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py\", line 5809, in _dropout\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\", line 4898, in where_v2\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 10083, in select_v2\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\", line 796, in _apply_op_helper\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\", line 670, in _create_op_internal\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 2652, in _create_op_internal\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 1160, in from_node_def\n\nThe tensor <tf.Tensor 'virtual_ensemble_model/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=predict_function, id=133006349326304), which is out of scope."
          ]
        }
      ],
      "source": [
        "Xresult = new_model.predict(input_data)\n",
        "# print(Xresult.shape)\n",
        "# Xresult"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-06T04:55:04.479155Z",
          "start_time": "2024-03-06T04:55:04.327107Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0xwyxfdxe4GY",
        "outputId": "494fc801-7e1a-44fc-a30a-68c37e52c184"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96711825, 0.44602729, 0.5387772 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "input_data"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-06T04:46:41.865457Z",
          "start_time": "2024-03-06T04:46:41.857454Z"
        },
        "id": "oLP7Rk5Ge4GZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a91457a-ce00-4f0d-e124-6495b1183b7a"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "/-*-/*-/*-/-*/-*/-*/-*/\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "vlUKvWhwe4Ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error:\n",
        "\n",
        "```\n",
        "TypeError: <tf.Tensor 'model_10/Layer_0/DropoutTrain/dropout/SelectV2:0' shape=(1, 128) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\n",
        "```\n",
        "\n",
        "\n",
        "Is due to the fact that TensorFlow's tf.function creates a new computational graph for the function it decorates. This means that any tensors created within the function are not accessible outside of it.  In your case, you're trying to access the output of a layer from a model (gen1) that was likely created within a tf.function. This is not allowed as per TensorFlow's execution model.  To resolve this issue, you need to ensure that the model gen1 is created outside of a tf.function context. If the model is being created within a tf.function decorated function, you should move the model creation outside of this function.  If you don't have control over where and how gen1 is created, an alternative solution would be to create a new model with the same architecture as gen1 but created outside of a tf.function context. You can then load the weights from gen1 into this new model and proceed with your operation."
      ],
      "metadata": {
        "id": "UdK0l62FuUus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assuming the generator is a model created within a tf.function context"
      ],
      "metadata": {
        "id": "KNJQG_fXuhjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generator(dropout_rate, dropout_type='bernoulli'):\n",
        "    gen_config = {\n",
        "            'drop_rate': dropout_rate,\n",
        "            # 'dropout_type': 'bernoulli_structured',\n",
        "            'dropout_type': dropout_type,\n",
        "            # 'drop_kwargs': {'patch_size': 3}\n",
        "    }\n",
        "    generator = RichMCDropFunc(**gen_config)\n",
        "    generator.build((None, 3))\n",
        "    return generator"
      ],
      "metadata": {
        "id": "QZChMqZGuTuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model with the same architecture\n",
        "new_gen = create_generator(0.1)\n",
        "new_gen.set_weights(gen1.get_weights())\n",
        "\n",
        "# Now you can create a new model that outputs from the 15th layer\n",
        "input_layer = new_gen.input\n",
        "output_layer = new_gen.layers[14].output  # Index is 14 because layer indexing starts from 0\n",
        "\n",
        "# Create a new model\n",
        "new_model = Model(input_layer, output_layer)\n",
        "\n",
        "# Now you can use `new_model` to predict on your data\n",
        "embedding_output = new_model.predict(input_data)\n",
        "\n",
        "embedding_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KobhdlvWukN5",
        "outputId": "2fc0c434-492c-458c-cecf-9b06b17a2135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n",
            "Layer 4\n",
            "1/1 [==============================] - 0s 139ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.1970878 , -0.24459776,  1.4919145 , -0.45148534, -0.08470431,\n",
              "         0.5635197 , -0.97210366, -1.3280557 ,  0.03235679,  0.44038948,\n",
              "         0.25111318, -0.95786685,  0.07753997,  0.84519356,  0.7116152 ,\n",
              "         0.12451969,  0.36327466,  0.2476968 ,  0.66545844,  0.59294915,\n",
              "         0.20050749, -0.19333921, -1.1475161 , -0.36302882, -0.20809755,\n",
              "         0.27293456,  0.11388439, -0.05502814, -0.6293955 ,  0.3655545 ,\n",
              "        -0.24131197, -0.70723915,  0.81003416,  0.01305694,  0.23496412,\n",
              "         0.11750372,  0.48235074, -0.71726525, -0.23201275, -0.3864569 ,\n",
              "        -0.610474  ,  0.04682522,  0.63666946,  0.11976689, -0.15143754,\n",
              "         0.8800062 , -1.1031467 ,  0.71379155, -0.1876362 , -0.6030136 ,\n",
              "        -1.0119    , -0.8003013 , -1.6790619 ,  0.15865615, -0.43839175,\n",
              "        -0.38478366, -0.9927331 , -0.36635554,  0.14383674, -0.4745398 ,\n",
              "        -0.06113171,  0.44382176,  1.4804621 ,  0.3410128 , -0.63060015,\n",
              "        -0.17406036,  0.56266207,  0.23368126, -0.09034918, -0.35166633,\n",
              "         0.16243301, -0.58938086,  0.16391195,  0.6122256 ,  0.3495356 ,\n",
              "        -0.61178213, -0.7904337 ,  0.07857372, -0.40339464,  0.5229167 ,\n",
              "         0.6587078 ,  0.38485208, -0.91372555,  0.12788087, -0.8028823 ,\n",
              "        -1.2219448 ,  0.7978337 , -0.57574004,  0.14275679, -0.7834109 ,\n",
              "        -0.62612504, -0.5674643 , -0.44275752, -0.05954045, -0.19031847,\n",
              "         1.0648754 , -0.02646644,  0.3530005 , -0.21100298,  0.42202204,\n",
              "         0.33368865, -1.10074   ,  0.4356286 , -1.0759858 ,  0.04292135,\n",
              "        -1.8498355 , -0.233995  , -0.10444291, -0.10260873,  0.29306424,\n",
              "        -0.6446469 , -1.1810502 , -1.2898937 , -0.42386284, -0.37519965,\n",
              "         0.13592279, -0.18804532,  1.3542979 , -0.27194625,  0.13501078,\n",
              "         0.23179305, -0.6872217 , -0.7548303 , -0.83482254,  0.34248298,\n",
              "        -0.22730899, -0.904828  ,  1.3286284 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}